18/02/28 22:12:35 INFO SparkContext: Running Spark version 2.2.0
18/02/28 22:12:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 22:12:35 INFO SparkContext: Submitted application: sparklyr
18/02/28 22:12:35 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 22:12:35 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 22:12:35 INFO SecurityManager: Changing view acls groups to: 
18/02/28 22:12:35 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 22:12:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 22:12:35 INFO Utils: Successfully started service 'sparkDriver' on port 63596.
18/02/28 22:12:35 INFO SparkEnv: Registering MapOutputTracker
18/02/28 22:12:36 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 22:12:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 22:12:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 22:12:36 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-f669d615-b281-4eec-a3c2-f8079bf1d018
18/02/28 22:12:36 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 22:12:36 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 22:12:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 22:12:36 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 22:12:36 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:63596/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852356327
18/02/28 22:12:36 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:63596/jars/sparklyr-2.2-2.11.jar with timestamp 1519852356328
18/02/28 22:12:36 INFO Executor: Starting executor ID driver on host localhost
18/02/28 22:12:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63601.
18/02/28 22:12:36 INFO NettyBlockTransferService: Server created on 127.0.0.1:63601
18/02/28 22:12:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 22:12:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63601, None)
18/02/28 22:12:36 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63601 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63601, None)
18/02/28 22:12:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63601, None)
18/02/28 22:12:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63601, None)
18/02/28 22:12:36 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 22:12:36 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 22:12:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 22:12:36 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 22:12:37 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 22:12:37 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 22:12:37 INFO ObjectStore: ObjectStore, initialize called
18/02/28 22:12:37 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 22:12:37 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 22:12:39 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 22:12:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:12:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:12:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:12:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:12:40 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 22:12:40 INFO ObjectStore: Initialized ObjectStore
18/02/28 22:12:40 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 22:12:40 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 22:12:40 INFO HiveMetaStore: Added admin role in metastore
18/02/28 22:12:40 INFO HiveMetaStore: Added public role in metastore
18/02/28 22:12:40 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 22:12:40 INFO HiveMetaStore: 0: get_all_databases
18/02/28 22:12:40 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 22:12:40 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 22:12:40 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 22:12:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:12:40 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/891227e9-9063-4ec2-95fe-0dcde33d2d88_resources
18/02/28 22:12:40 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/891227e9-9063-4ec2-95fe-0dcde33d2d88
18/02/28 22:12:40 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/891227e9-9063-4ec2-95fe-0dcde33d2d88
18/02/28 22:12:40 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/891227e9-9063-4ec2-95fe-0dcde33d2d88/_tmp_space.db
18/02/28 22:12:40 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:12:40 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:12:40 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:12:40 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 22:12:40 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 22:12:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 22:12:40 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/5bc5d007-92e6-42ba-9249-d231aa954c8b_resources
18/02/28 22:12:41 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/5bc5d007-92e6-42ba-9249-d231aa954c8b
18/02/28 22:12:41 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/5bc5d007-92e6-42ba-9249-d231aa954c8b
18/02/28 22:12:41 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/5bc5d007-92e6-42ba-9249-d231aa954c8b/_tmp_space.db
18/02/28 22:12:41 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:12:41 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 22:12:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:12:42 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:12:42 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:12:42 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:12:42 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:12:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:12:42 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:12:42 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:12:42 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 22:12:42 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 22:12:42 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:12:42 INFO DAGScheduler: Missing parents: List()
18/02/28 22:12:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 22:12:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 22:12:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 22:12:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:63601 (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:12:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 22:12:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:12:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 22:12:42 INFO Executor: Fetching spark://127.0.0.1:63596/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852356327
18/02/28 22:12:42 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63596 after 10 ms (0 ms spent in bootstraps)
18/02/28 22:12:42 INFO Utils: Fetching spark://127.0.0.1:63596/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-0cdff026-0fc2-4047-9a07-b6573428fafb/userFiles-4da2b456-3d5d-489a-be52-2c92b2cc8017/fetchFileTemp9210129363228262187.tmp
18/02/28 22:12:42 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-0cdff026-0fc2-4047-9a07-b6573428fafb/userFiles-4da2b456-3d5d-489a-be52-2c92b2cc8017/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 22:12:42 INFO Executor: Fetching spark://127.0.0.1:63596/jars/sparklyr-2.2-2.11.jar with timestamp 1519852356328
18/02/28 22:12:42 INFO Utils: Fetching spark://127.0.0.1:63596/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-0cdff026-0fc2-4047-9a07-b6573428fafb/userFiles-4da2b456-3d5d-489a-be52-2c92b2cc8017/fetchFileTemp5817135886826361371.tmp
18/02/28 22:12:42 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-0cdff026-0fc2-4047-9a07-b6573428fafb/userFiles-4da2b456-3d5d-489a-be52-2c92b2cc8017/sparklyr-2.2-2.11.jar to class loader
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 168.280378 ms
18/02/28 22:12:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 22:12:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 411 ms on localhost (executor driver) (1/1)
18/02/28 22:12:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 22:12:43 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.428 s
18/02/28 22:12:43 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.565272 s
18/02/28 22:12:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:43 INFO SparkSqlParser: Parsing command: test
18/02/28 22:12:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:43 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:12:43 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:12:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:63601 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:12:43 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 22:12:43 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 16.390371 ms
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 8.82418 ms
18/02/28 22:12:43 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 22:12:43 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:12:43 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 22:12:43 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:12:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 22:12:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 22:12:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 22:12:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:63601 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:12:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 22:12:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:12:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 8.038458 ms
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 16.747207 ms
18/02/28 22:12:43 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 22:12:43 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:63601 (size: 384.0 B, free: 366.3 MB)
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 4.034105 ms
18/02/28 22:12:43 INFO CodeGenerator: Code generated in 16.719612 ms
18/02/28 22:12:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 22:12:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 139 ms on localhost (executor driver) (1/1)
18/02/28 22:12:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 22:12:43 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.140 s
18/02/28 22:12:43 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:12:43 INFO DAGScheduler: running: Set()
18/02/28 22:12:43 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 22:12:43 INFO DAGScheduler: failed: Set()
18/02/28 22:12:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 22:12:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:63601 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:12:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 22:12:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:12:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 22:12:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:12:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 22:12:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1624 bytes result sent to driver
18/02/28 22:12:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
18/02/28 22:12:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 22:12:43 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
18/02/28 22:12:43 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.214567 s
18/02/28 22:12:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:43 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:12:43 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:12:43 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:12:43 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:12:43 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 22:12:43 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:12:43 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 22:12:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 22:12:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 22:12:43 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:12:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 22:12:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:63601 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:12:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 22:12:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:12:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 22:12:44 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:12:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 22:12:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
18/02/28 22:12:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 22:12:44 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.012 s
18/02/28 22:12:44 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:12:44 INFO DAGScheduler: running: Set()
18/02/28 22:12:44 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 22:12:44 INFO DAGScheduler: failed: Set()
18/02/28 22:12:44 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 22:12:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:12:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:12:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:63601 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:12:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:44 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 22:12:44 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:12:44 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 22:12:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:12:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:12:44 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
18/02/28 22:12:44 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:12:44 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 22:12:44 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.005 s
18/02/28 22:12:44 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.034703 s
18/02/28 22:12:44 INFO CodeGenerator: Code generated in 6.968626 ms
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1687b3473c9e
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1687b3473c9e` AS `zzz2`
WHERE (0 = 1)
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1687b3473c9e`
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1687b3b88abaa
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1687b3b88abaa` AS `zzz3`
WHERE (0 = 1)
18/02/28 22:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:12:44 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_1687b3b88abaa`
18/02/28 22:12:44 INFO CodeGenerator: Code generated in 21.821757 ms
18/02/28 22:12:44 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:12:44 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:12:44 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 22:12:44 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:12:44 INFO DAGScheduler: Missing parents: List()
18/02/28 22:12:44 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 22:12:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 22:12:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 22:12:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:63601 (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:12:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 22:12:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:12:44 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 22:12:44 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:12:44 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 22:12:44 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:12:44 INFO CodeGenerator: Code generated in 15.830672 ms
18/02/28 22:12:44 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 22:12:44 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
18/02/28 22:12:44 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 22:12:44 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.034 s
18/02/28 22:12:44 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.040290 s
18/02/28 22:12:44 INFO CodeGenerator: Code generated in 10.86341 ms
18/02/28 22:12:45 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 22:12:45 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 22:12:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 22:12:45 INFO MemoryStore: MemoryStore cleared
18/02/28 22:12:45 INFO BlockManager: BlockManager stopped
18/02/28 22:12:45 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 22:12:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 22:12:45 INFO SparkContext: Successfully stopped SparkContext
18/02/28 22:12:45 INFO ShutdownHookManager: Shutdown hook called
18/02/28 22:12:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-0cdff026-0fc2-4047-9a07-b6573428fafb
18/02/28 22:14:21 INFO SparkContext: Running Spark version 2.2.0
18/02/28 22:14:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 22:14:21 INFO SparkContext: Submitted application: sparklyr
18/02/28 22:14:21 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 22:14:21 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 22:14:21 INFO SecurityManager: Changing view acls groups to: 
18/02/28 22:14:21 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 22:14:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 22:14:21 INFO Utils: Successfully started service 'sparkDriver' on port 63736.
18/02/28 22:14:21 INFO SparkEnv: Registering MapOutputTracker
18/02/28 22:14:21 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 22:14:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 22:14:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 22:14:21 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-938b4c5d-8593-4592-bce4-dce542094c1c
18/02/28 22:14:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 22:14:21 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 22:14:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 22:14:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 22:14:21 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:63736/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852461829
18/02/28 22:14:21 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:63736/jars/sparklyr-2.2-2.11.jar with timestamp 1519852461830
18/02/28 22:14:21 INFO Executor: Starting executor ID driver on host localhost
18/02/28 22:14:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63737.
18/02/28 22:14:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:63737
18/02/28 22:14:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 22:14:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63737, None)
18/02/28 22:14:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63737 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63737, None)
18/02/28 22:14:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63737, None)
18/02/28 22:14:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63737, None)
18/02/28 22:14:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 22:14:22 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 22:14:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 22:14:22 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 22:14:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 22:14:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 22:14:23 INFO ObjectStore: ObjectStore, initialize called
18/02/28 22:14:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 22:14:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 22:14:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 22:14:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:14:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:14:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:14:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:14:25 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 22:14:25 INFO ObjectStore: Initialized ObjectStore
18/02/28 22:14:25 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 22:14:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 22:14:26 INFO HiveMetaStore: Added admin role in metastore
18/02/28 22:14:26 INFO HiveMetaStore: Added public role in metastore
18/02/28 22:14:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 22:14:26 INFO HiveMetaStore: 0: get_all_databases
18/02/28 22:14:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 22:14:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 22:14:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 22:14:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:14:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/d1d8ce78-1850-4804-bb3d-2b1d4b5263e4_resources
18/02/28 22:14:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/d1d8ce78-1850-4804-bb3d-2b1d4b5263e4
18/02/28 22:14:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/d1d8ce78-1850-4804-bb3d-2b1d4b5263e4
18/02/28 22:14:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/d1d8ce78-1850-4804-bb3d-2b1d4b5263e4/_tmp_space.db
18/02/28 22:14:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:14:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:26 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 22:14:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 22:14:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 22:14:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/8340f015-e417-4f1e-a51b-add555e603e5_resources
18/02/28 22:14:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/8340f015-e417-4f1e-a51b-add555e603e5
18/02/28 22:14:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/8340f015-e417-4f1e-a51b-add555e603e5
18/02/28 22:14:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/8340f015-e417-4f1e-a51b-add555e603e5/_tmp_space.db
18/02/28 22:14:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:14:26 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 22:14:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:14:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:27 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:27 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:27 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:14:27 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:14:28 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:14:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 22:14:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 22:14:28 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:14:28 INFO DAGScheduler: Missing parents: List()
18/02/28 22:14:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 22:14:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 22:14:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 22:14:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:63737 (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:14:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 22:14:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:14:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 22:14:28 INFO Executor: Fetching spark://127.0.0.1:63736/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852461829
18/02/28 22:14:28 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63736 after 11 ms (0 ms spent in bootstraps)
18/02/28 22:14:28 INFO Utils: Fetching spark://127.0.0.1:63736/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-bd02c915-541a-4b3d-8a1c-bc106a674100/userFiles-46325c9a-b2e4-49eb-9a5b-76397387c8e3/fetchFileTemp3315109277676928705.tmp
18/02/28 22:14:28 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-bd02c915-541a-4b3d-8a1c-bc106a674100/userFiles-46325c9a-b2e4-49eb-9a5b-76397387c8e3/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 22:14:28 INFO Executor: Fetching spark://127.0.0.1:63736/jars/sparklyr-2.2-2.11.jar with timestamp 1519852461830
18/02/28 22:14:28 INFO Utils: Fetching spark://127.0.0.1:63736/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-bd02c915-541a-4b3d-8a1c-bc106a674100/userFiles-46325c9a-b2e4-49eb-9a5b-76397387c8e3/fetchFileTemp6693680651369826300.tmp
18/02/28 22:14:28 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-bd02c915-541a-4b3d-8a1c-bc106a674100/userFiles-46325c9a-b2e4-49eb-9a5b-76397387c8e3/sparklyr-2.2-2.11.jar to class loader
18/02/28 22:14:28 INFO CodeGenerator: Code generated in 167.684691 ms
18/02/28 22:14:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 22:14:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 425 ms on localhost (executor driver) (1/1)
18/02/28 22:14:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 22:14:28 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.441 s
18/02/28 22:14:28 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.603317 s
18/02/28 22:14:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: test
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:14:29 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 22:14:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:63737 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:14:29 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 17.774374 ms
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 9.38848 ms
18/02/28 22:14:29 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 22:14:29 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:14:29 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 22:14:29 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:14:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 22:14:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 22:14:29 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 22:14:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:14:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 22:14:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:14:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 8.188967 ms
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 17.397305 ms
18/02/28 22:14:29 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 22:14:29 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.3 MB)
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 4.252401 ms
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 17.39311 ms
18/02/28 22:14:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 22:14:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 140 ms on localhost (executor driver) (1/1)
18/02/28 22:14:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 22:14:29 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.142 s
18/02/28 22:14:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:14:29 INFO DAGScheduler: running: Set()
18/02/28 22:14:29 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 22:14:29 INFO DAGScheduler: failed: Set()
18/02/28 22:14:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 22:14:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:14:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 22:14:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:14:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 22:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/02/28 22:14:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
18/02/28 22:14:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
18/02/28 22:14:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 22:14:29 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.032 s
18/02/28 22:14:29 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.218424 s
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:14:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:29 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:14:29 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 22:14:29 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:14:29 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 22:14:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 22:14:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 22:14:29 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 22:14:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:14:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 22:14:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:14:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 22:14:29 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:14:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 22:14:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
18/02/28 22:14:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 22:14:29 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.012 s
18/02/28 22:14:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:14:29 INFO DAGScheduler: running: Set()
18/02/28 22:14:29 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 22:14:29 INFO DAGScheduler: failed: Set()
18/02/28 22:14:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:14:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:14:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:14:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 22:14:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:14:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 22:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:14:29 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
18/02/28 22:14:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:14:29 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 22:14:29 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.006 s
18/02/28 22:14:29 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.034102 s
18/02/28 22:14:29 INFO CodeGenerator: Code generated in 6.373117 ms
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d28166ff8
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d28166ff8` AS `zzz2`
WHERE (0 = 1)
18/02/28 22:14:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d28166ff8`
18/02/28 22:14:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d36d1e368
18/02/28 22:14:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d36d1e368` AS `zzz3`
WHERE (0 = 1)
18/02/28 22:14:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:30 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_1669d36d1e368`
18/02/28 22:14:30 INFO CodeGenerator: Code generated in 20.115034 ms
18/02/28 22:14:30 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:14:30 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:14:30 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 22:14:30 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:14:30 INFO DAGScheduler: Missing parents: List()
18/02/28 22:14:30 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 22:14:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 22:14:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 22:14:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:63737 (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:14:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 22:14:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:14:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 22:14:30 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:14:30 INFO CodeGenerator: Code generated in 14.687913 ms
18/02/28 22:14:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 22:14:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (executor driver) (1/1)
18/02/28 22:14:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 22:14:30 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.033 s
18/02/28 22:14:30 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.040025 s
18/02/28 22:14:30 INFO CodeGenerator: Code generated in 13.449609 ms
18/02/28 22:14:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:14:30 INFO CodeGenerator: Code generated in 7.408267 ms
18/02/28 22:14:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:14:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:14:30 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:14:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:14:37 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:14:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:14:37 INFO DAGScheduler: Got job 4 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:14:37 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:211)
18/02/28 22:14:37 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:14:37 INFO DAGScheduler: Missing parents: List()
18/02/28 22:14:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:211), which has no missing parents
18/02/28 22:14:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.3 KB, free 366.2 MB)
18/02/28 22:14:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KB, free 366.2 MB)
18/02/28 22:14:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.3 MB)
18/02/28 22:14:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/02/28 22:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:14:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/02/28 22:14:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:14:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/02/28 22:14:37 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:14:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1232 bytes result sent to driver
18/02/28 22:14:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:14:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/02/28 22:14:37 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:211) finished in 0.005 s
18/02/28 22:14:37 INFO DAGScheduler: Job 4 finished: collect at utils.scala:211, took 0.011573 s
18/02/28 22:14:37 INFO CodeGenerator: Code generated in 5.556933 ms
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:24 INFO CodeGenerator: Code generated in 5.320231 ms
18/02/28 22:15:24 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:15:24 INFO DAGScheduler: Got job 5 (collect at utils.scala:58) with 3 output partitions
18/02/28 22:15:24 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:58)
18/02/28 22:15:24 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:24 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:24 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at map at utils.scala:55), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.5 KB, free 366.2 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KB, free 366.2 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:63737 (size: 3.6 KB, free: 366.3 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 3 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:24 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/02/28 22:15:24 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
18/02/28 22:15:24 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
18/02/28 22:15:24 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 999 bytes result sent to driver
18/02/28 22:15:24 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 977 bytes result sent to driver
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 999 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 7 ms on localhost (executor driver) (1/3)
18/02/28 22:15:24 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 7 ms on localhost (executor driver) (2/3)
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (3/3)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:58) finished in 0.009 s
18/02/28 22:15:24 INFO DAGScheduler: Job 5 finished: collect at utils.scala:58, took 0.015307 s
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO MapPartitionsRDD: Removing RDD 9 from persistence list
18/02/28 22:15:24 INFO BlockManager: Removing RDD 9
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: test
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:15:24 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 22:15:24 INFO DAGScheduler: Registering RDD 39 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:15:24 INFO DAGScheduler: Got job 6 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 22:15:24 INFO DAGScheduler: Final stage: ResultStage 9 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:15:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
18/02/28 22:15:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
18/02/28 22:15:24 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 366.2 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
18/02/28 22:15:24 INFO MemoryStore: Block rdd_36_0 stored as values in memory (estimated size 384.0 B, free 366.2 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added rdd_36_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.3 MB)
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2285 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 12 ms on localhost (executor driver) (1/1)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ShuffleMapStage 8 (sql at NativeMethodAccessorImpl.java:0) finished in 0.013 s
18/02/28 22:15:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:24 INFO DAGScheduler: running: Set()
18/02/28 22:15:24 INFO DAGScheduler: waiting: Set(ResultStage 9)
18/02/28 22:15:24 INFO DAGScheduler: failed: Set()
18/02/28 22:15:24 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 9.0 (TID 11)
18/02/28 22:15:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 9.0 (TID 11). 1538 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ResultStage 9 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
18/02/28 22:15:24 INFO DAGScheduler: Job 6 finished: sql at NativeMethodAccessorImpl.java:0, took 0.032872 s
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:24 INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:211)
18/02/28 22:15:24 INFO DAGScheduler: Got job 7 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:24 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:211)
18/02/28 22:15:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/02/28 22:15:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/02/28 22:15:24 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[45] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 14.6 KB, free 366.1 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.1 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.2 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[45] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 10.0 (TID 12)
18/02/28 22:15:24 INFO BlockManager: Found block rdd_36_0 locally
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 10.0 (TID 12). 1690 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:211) finished in 0.008 s
18/02/28 22:15:24 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:24 INFO DAGScheduler: running: Set()
18/02/28 22:15:24 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/02/28 22:15:24 INFO DAGScheduler: failed: Set()
18/02/28 22:15:24 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[48] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 366.1 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.1 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[48] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 11.0 (TID 13)
18/02/28 22:15:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 11.0 (TID 13). 1581 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:211) finished in 0.006 s
18/02/28 22:15:24 INFO DAGScheduler: Job 7 finished: collect at utils.scala:211, took 0.025126 s
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz4`
WHERE (0 = 1)
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:24 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:24 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:15:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:24 INFO DAGScheduler: Got job 8 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:24 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:211)
18/02/28 22:15:24 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:24 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:24 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.3 KB, free 366.1 MB)
18/02/28 22:15:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.4 KB, free 366.1 MB)
18/02/28 22:15:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:15:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:24 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/02/28 22:15:24 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:15:24 INFO Executor: Running task 0.0 in stage 12.0 (TID 14)
18/02/28 22:15:24 INFO BlockManager: Found block rdd_36_0 locally
18/02/28 22:15:24 INFO Executor: Finished task 0.0 in stage 12.0 (TID 14). 1232 bytes result sent to driver
18/02/28 22:15:24 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:15:24 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/02/28 22:15:24 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:15:24 INFO DAGScheduler: Job 8 finished: collect at utils.scala:211, took 0.011383 s
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:36 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:36 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:36 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:36 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:36 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:36 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:15:36 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 3 output partitions
18/02/28 22:15:36 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:58)
18/02/28 22:15:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:36 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:36 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at map at utils.scala:55), which has no missing parents
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 6.5 KB, free 366.1 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.6 KB, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:63737 (size: 3.6 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:36 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:36 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 17, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
18/02/28 22:15:36 INFO Executor: Running task 2.0 in stage 13.0 (TID 17)
18/02/28 22:15:36 INFO Executor: Running task 1.0 in stage 13.0 (TID 16)
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 13.0 (TID 15)
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 13.0 (TID 15). 999 bytes result sent to driver
18/02/28 22:15:36 INFO Executor: Finished task 2.0 in stage 13.0 (TID 17). 977 bytes result sent to driver
18/02/28 22:15:36 INFO Executor: Finished task 1.0 in stage 13.0 (TID 16). 999 bytes result sent to driver
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 7 ms on localhost (executor driver) (1/3)
18/02/28 22:15:36 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 16) in 6 ms on localhost (executor driver) (2/3)
18/02/28 22:15:36 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 17) in 7 ms on localhost (executor driver) (3/3)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:58) finished in 0.008 s
18/02/28 22:15:36 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.015542 s
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO MapPartitionsRDD: Removing RDD 36 from persistence list
18/02/28 22:15:36 INFO BlockManager: Removing RDD 36
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: test
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:15:36 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 22:15:36 INFO DAGScheduler: Registering RDD 63 (sql at <unknown>:0)
18/02/28 22:15:36 INFO DAGScheduler: Got job 10 (sql at <unknown>:0) with 1 output partitions
18/02/28 22:15:36 INFO DAGScheduler: Final stage: ResultStage 15 (sql at <unknown>:0)
18/02/28 22:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/02/28 22:15:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/02/28 22:15:36 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[63] at sql at <unknown>:0), which has no missing parents
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.6 KB, free 366.1 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[63] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 14.0 (TID 18)
18/02/28 22:15:36 INFO MemoryStore: Block rdd_60_0 stored as values in memory (estimated size 384.0 B, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added rdd_60_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.2 MB)
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 14.0 (TID 18). 2285 bytes result sent to driver
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 18) in 11 ms on localhost (executor driver) (1/1)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO DAGScheduler: ShuffleMapStage 14 (sql at <unknown>:0) finished in 0.011 s
18/02/28 22:15:36 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:36 INFO DAGScheduler: running: Set()
18/02/28 22:15:36 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/02/28 22:15:36 INFO DAGScheduler: failed: Set()
18/02/28 22:15:36 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[66] at sql at <unknown>:0), which has no missing parents
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 366.1 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[66] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 19, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 15.0 (TID 19)
18/02/28 22:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 15.0 (TID 19). 1581 bytes result sent to driver
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO DAGScheduler: ResultStage 15 (sql at <unknown>:0) finished in 0.007 s
18/02/28 22:15:36 INFO DAGScheduler: Job 10 finished: sql at <unknown>:0, took 0.030336 s
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:15:36 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:36 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 251
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 427
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 257
18/02/28 22:15:36 INFO ContextCleaner: Cleaned shuffle 2
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 435
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 486
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 428
18/02/28 22:15:36 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:211)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 398
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 224
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 430
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 260
18/02/28 22:15:36 INFO DAGScheduler: Got job 11 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:36 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:211)
18/02/28 22:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
18/02/28 22:15:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:63737 in memory (size: 3.6 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 425
18/02/28 22:15:36 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[69] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 426
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:63737 in memory (size: 9.2 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.6 KB, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.1 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[69] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 253
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.2 MB)
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 254
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 312
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 16.0 (TID 20)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 255
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 261
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 429
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 259
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 262
18/02/28 22:15:36 INFO BlockManager: Found block rdd_60_0 locally
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 263
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 436
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 431
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 256
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 258
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:63737 in memory (size: 3.6 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 434
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 16.0 (TID 20). 1690 bytes result sent to driver
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 437
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 432
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 112
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 20) in 10 ms on localhost (executor driver) (1/1)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:211) finished in 0.011 s
18/02/28 22:15:36 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:36 INFO DAGScheduler: running: Set()
18/02/28 22:15:36 INFO DAGScheduler: waiting: Set(ResultStage 17)
18/02/28 22:15:36 INFO DAGScheduler: failed: Set()
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 252
18/02/28 22:15:36 INFO ContextCleaner: Cleaned accumulator 433
18/02/28 22:15:36 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:36 INFO ContextCleaner: Cleaned shuffle 4
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 17.0 (TID 21)
18/02/28 22:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 17.0 (TID 21). 1624 bytes result sent to driver
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 21) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:211) finished in 0.006 s
18/02/28 22:15:36 INFO DAGScheduler: Job 11 finished: collect at utils.scala:211, took 0.028708 s
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz5`
WHERE (0 = 1)
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d52a3c7b5
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d52a3c7b5` AS `zzz6`
WHERE (0 = 1)
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d52a3c7b5`
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d77d64ff4
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d77d64ff4` AS `zzz7`
WHERE (0 = 1)
18/02/28 22:15:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:36 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_1669d77d64ff4`
18/02/28 22:15:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:36 INFO DAGScheduler: Got job 12 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:36 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:211)
18/02/28 22:15:36 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:36 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:36 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[75] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 22:15:36 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 22:15:36 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:63737 (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:15:36 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[75] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:36 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/02/28 22:15:36 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:15:36 INFO Executor: Running task 0.0 in stage 18.0 (TID 22)
18/02/28 22:15:36 INFO BlockManager: Found block rdd_60_0 locally
18/02/28 22:15:36 INFO Executor: Finished task 0.0 in stage 18.0 (TID 22). 1402 bytes result sent to driver
18/02/28 22:15:36 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:15:36 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/02/28 22:15:36 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:211) finished in 0.005 s
18/02/28 22:15:36 INFO DAGScheduler: Job 12 finished: collect at utils.scala:211, took 0.011313 s
18/02/28 22:15:36 INFO CodeGenerator: Code generated in 11.273022 ms
18/02/28 22:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:37 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:37 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:37 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:37 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:37 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:37 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:15:37 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:37 INFO DAGScheduler: Got job 13 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:37 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:211)
18/02/28 22:15:37 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:37 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:37 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[77] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:37 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.3 KB, free 366.2 MB)
18/02/28 22:15:37 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.4 KB, free 366.2 MB)
18/02/28 22:15:37 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.3 MB)
18/02/28 22:15:37 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[77] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:37 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/02/28 22:15:37 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:15:37 INFO Executor: Running task 0.0 in stage 19.0 (TID 23)
18/02/28 22:15:37 INFO BlockManager: Found block rdd_60_0 locally
18/02/28 22:15:37 INFO Executor: Finished task 0.0 in stage 19.0 (TID 23). 1232 bytes result sent to driver
18/02/28 22:15:37 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 23) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:15:37 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/02/28 22:15:37 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:15:37 INFO DAGScheduler: Job 13 finished: collect at utils.scala:211, took 0.009933 s
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:46 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:46 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:46 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:46 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:15:46 INFO DAGScheduler: Got job 14 (collect at utils.scala:58) with 5 output partitions
18/02/28 22:15:46 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:58)
18/02/28 22:15:46 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:46 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:46 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[82] at map at utils.scala:55), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.8 KB, free 366.2 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.6 KB, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:63737 (size: 3.6 KB, free: 366.3 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 20 (MapPartitionsRDD[82] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 20.0 with 5 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:46 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:46 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 26, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:46 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 27, localhost, executor driver, partition 3, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:15:46 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 28, localhost, executor driver, partition 4, PROCESS_LOCAL, 5011 bytes)
18/02/28 22:15:46 INFO Executor: Running task 1.0 in stage 20.0 (TID 25)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 20.0 (TID 24)
18/02/28 22:15:46 INFO Executor: Running task 2.0 in stage 20.0 (TID 26)
18/02/28 22:15:46 INFO Executor: Running task 3.0 in stage 20.0 (TID 27)
18/02/28 22:15:46 INFO Executor: Running task 4.0 in stage 20.0 (TID 28)
18/02/28 22:15:46 INFO Executor: Finished task 2.0 in stage 20.0 (TID 26). 999 bytes result sent to driver
18/02/28 22:15:46 INFO Executor: Finished task 4.0 in stage 20.0 (TID 28). 977 bytes result sent to driver
18/02/28 22:15:46 INFO Executor: Finished task 3.0 in stage 20.0 (TID 27). 999 bytes result sent to driver
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 20.0 (TID 24). 999 bytes result sent to driver
18/02/28 22:15:46 INFO Executor: Finished task 1.0 in stage 20.0 (TID 25). 999 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 26) in 5 ms on localhost (executor driver) (1/5)
18/02/28 22:15:46 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 28) in 5 ms on localhost (executor driver) (2/5)
18/02/28 22:15:46 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 27) in 5 ms on localhost (executor driver) (3/5)
18/02/28 22:15:46 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 25) in 6 ms on localhost (executor driver) (4/5)
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 24) in 7 ms on localhost (executor driver) (5/5)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:58) finished in 0.007 s
18/02/28 22:15:46 INFO DAGScheduler: Job 14 finished: collect at utils.scala:58, took 0.012098 s
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO MapPartitionsRDD: Removing RDD 60 from persistence list
18/02/28 22:15:46 INFO BlockManager: Removing RDD 60
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: test
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:15:46 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 22:15:46 INFO DAGScheduler: Registering RDD 90 (sql at <unknown>:0)
18/02/28 22:15:46 INFO DAGScheduler: Got job 15 (sql at <unknown>:0) with 1 output partitions
18/02/28 22:15:46 INFO DAGScheduler: Final stage: ResultStage 22 (sql at <unknown>:0)
18/02/28 22:15:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
18/02/28 22:15:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
18/02/28 22:15:46 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[90] at sql at <unknown>:0), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.6 KB, free 366.2 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.4 KB, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:63737 (size: 7.4 KB, free: 366.3 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[90] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 21.0 (TID 29)
18/02/28 22:15:46 INFO MemoryStore: Block rdd_87_0 stored as values in memory (estimated size 384.0 B, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added rdd_87_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.3 MB)
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 21.0 (TID 29). 2285 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 29) in 9 ms on localhost (executor driver) (1/1)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ShuffleMapStage 21 (sql at <unknown>:0) finished in 0.009 s
18/02/28 22:15:46 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:46 INFO DAGScheduler: running: Set()
18/02/28 22:15:46 INFO DAGScheduler: waiting: Set(ResultStage 22)
18/02/28 22:15:46 INFO DAGScheduler: failed: Set()
18/02/28 22:15:46 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[93] at sql at <unknown>:0), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[93] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 30, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 22.0 (TID 30)
18/02/28 22:15:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 22.0 (TID 30). 1581 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 30) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ResultStage 22 (sql at <unknown>:0) finished in 0.005 s
18/02/28 22:15:46 INFO DAGScheduler: Job 15 finished: sql at <unknown>:0, took 0.026062 s
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:15:46 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:46 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:46 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:46 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:211)
18/02/28 22:15:46 INFO DAGScheduler: Got job 16 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:46 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:211)
18/02/28 22:15:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
18/02/28 22:15:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
18/02/28 22:15:46 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[96] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 14.6 KB, free 366.2 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:63737 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[96] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 23.0 (TID 31)
18/02/28 22:15:46 INFO BlockManager: Found block rdd_87_0 locally
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 23.0 (TID 31). 1690 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 31) in 6 ms on localhost (executor driver) (1/1)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:211) finished in 0.007 s
18/02/28 22:15:46 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:15:46 INFO DAGScheduler: running: Set()
18/02/28 22:15:46 INFO DAGScheduler: waiting: Set(ResultStage 24)
18/02/28 22:15:46 INFO DAGScheduler: failed: Set()
18/02/28 22:15:46 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[99] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[99] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 32, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 24.0 (TID 32)
18/02/28 22:15:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 24.0 (TID 32). 1581 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:15:46 INFO DAGScheduler: Job 16 finished: collect at utils.scala:211, took 0.022344 s
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz8`
WHERE (0 = 1)
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d145a6805
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d145a6805` AS `zzz9`
WHERE (0 = 1)
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d145a6805`
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d49798afd
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d49798afd` AS `zzz10`
WHERE (0 = 1)
18/02/28 22:15:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:46 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_1669d49798afd`
18/02/28 22:15:46 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:46 INFO DAGScheduler: Got job 17 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:46 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:211)
18/02/28 22:15:46 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:46 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:46 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[102] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.8 KB, free 366.1 MB)
18/02/28 22:15:46 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.1 MB)
18/02/28 22:15:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:63737 (size: 9.2 KB, free: 366.2 MB)
18/02/28 22:15:46 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[102] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:46 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/02/28 22:15:46 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:15:46 INFO Executor: Running task 0.0 in stage 25.0 (TID 33)
18/02/28 22:15:46 INFO BlockManager: Found block rdd_87_0 locally
18/02/28 22:15:46 INFO Executor: Finished task 0.0 in stage 25.0 (TID 33). 1402 bytes result sent to driver
18/02/28 22:15:46 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:15:46 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/02/28 22:15:46 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:15:46 INFO DAGScheduler: Job 17 finished: collect at utils.scala:211, took 0.010112 s
18/02/28 22:15:47 INFO CodeGenerator: Code generated in 9.287972 ms
18/02/28 22:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:15:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:47 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:47 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:15:47 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:15:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:15:47 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:15:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:15:47 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:15:47 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:15:47 INFO DAGScheduler: Got job 18 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:15:47 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:211)
18/02/28 22:15:47 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:15:47 INFO DAGScheduler: Missing parents: List()
18/02/28 22:15:47 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[104] at collect at utils.scala:211), which has no missing parents
18/02/28 22:15:47 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 10.3 KB, free 366.1 MB)
18/02/28 22:15:47 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.4 KB, free 366.1 MB)
18/02/28 22:15:47 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:15:47 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
18/02/28 22:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[104] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:15:47 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/02/28 22:15:47 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:15:47 INFO Executor: Running task 0.0 in stage 26.0 (TID 34)
18/02/28 22:15:47 INFO BlockManager: Found block rdd_87_0 locally
18/02/28 22:15:47 INFO Executor: Finished task 0.0 in stage 26.0 (TID 34). 1189 bytes result sent to driver
18/02/28 22:15:47 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 34) in 3 ms on localhost (executor driver) (1/1)
18/02/28 22:15:47 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/02/28 22:15:47 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:211) finished in 0.003 s
18/02/28 22:15:47 INFO DAGScheduler: Job 18 finished: collect at utils.scala:211, took 0.008282 s
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:16:23 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:16:23 INFO DAGScheduler: Got job 19 (collect at utils.scala:58) with 7 output partitions
18/02/28 22:16:23 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:58)
18/02/28 22:16:23 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:16:23 INFO DAGScheduler: Missing parents: List()
18/02/28 22:16:23 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[109] at map at utils.scala:55), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 7.0 KB, free 366.1 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.1 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 27 (MapPartitionsRDD[109] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 27.0 with 7 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 37, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 38, localhost, executor driver, partition 3, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 39, localhost, executor driver, partition 4, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 40, localhost, executor driver, partition 5, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:16:23 INFO TaskSetManager: Starting task 6.0 in stage 27.0 (TID 41, localhost, executor driver, partition 6, PROCESS_LOCAL, 5011 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 27.0 (TID 35)
18/02/28 22:16:23 INFO Executor: Running task 1.0 in stage 27.0 (TID 36)
18/02/28 22:16:23 INFO Executor: Running task 3.0 in stage 27.0 (TID 38)
18/02/28 22:16:23 INFO Executor: Running task 4.0 in stage 27.0 (TID 39)
18/02/28 22:16:23 INFO Executor: Running task 5.0 in stage 27.0 (TID 40)
18/02/28 22:16:23 INFO Executor: Running task 2.0 in stage 27.0 (TID 37)
18/02/28 22:16:23 INFO Executor: Running task 6.0 in stage 27.0 (TID 41)
18/02/28 22:16:23 INFO Executor: Finished task 1.0 in stage 27.0 (TID 36). 956 bytes result sent to driver
18/02/28 22:16:23 INFO Executor: Finished task 4.0 in stage 27.0 (TID 39). 956 bytes result sent to driver
18/02/28 22:16:23 INFO Executor: Finished task 2.0 in stage 27.0 (TID 37). 956 bytes result sent to driver
18/02/28 22:16:23 INFO Executor: Finished task 6.0 in stage 27.0 (TID 41). 977 bytes result sent to driver
18/02/28 22:16:23 INFO Executor: Finished task 5.0 in stage 27.0 (TID 40). 956 bytes result sent to driver
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 27.0 (TID 35). 956 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 39) in 5 ms on localhost (executor driver) (1/7)
18/02/28 22:16:23 INFO Executor: Finished task 3.0 in stage 27.0 (TID 38). 956 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 36) in 6 ms on localhost (executor driver) (2/7)
18/02/28 22:16:23 INFO TaskSetManager: Finished task 6.0 in stage 27.0 (TID 41) in 5 ms on localhost (executor driver) (3/7)
18/02/28 22:16:23 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 37) in 5 ms on localhost (executor driver) (4/7)
18/02/28 22:16:23 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 40) in 6 ms on localhost (executor driver) (5/7)
18/02/28 22:16:23 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 38) in 6 ms on localhost (executor driver) (6/7)
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 35) in 7 ms on localhost (executor driver) (7/7)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:58) finished in 0.007 s
18/02/28 22:16:23 INFO DAGScheduler: Job 19 finished: collect at utils.scala:58, took 0.011716 s
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO MapPartitionsRDD: Removing RDD 87 from persistence list
18/02/28 22:16:23 INFO BlockManager: Removing RDD 87
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: test
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:16:23 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 22:16:23 INFO DAGScheduler: Registering RDD 117 (sql at <unknown>:0)
18/02/28 22:16:23 INFO DAGScheduler: Got job 20 (sql at <unknown>:0) with 1 output partitions
18/02/28 22:16:23 INFO DAGScheduler: Final stage: ResultStage 29 (sql at <unknown>:0)
18/02/28 22:16:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
18/02/28 22:16:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
18/02/28 22:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[117] at sql at <unknown>:0), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 14.6 KB, free 366.1 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 7.4 KB, free 366.1 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:63737 (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[117] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 28.0 (TID 42)
18/02/28 22:16:23 INFO MemoryStore: Block rdd_114_0 stored as values in memory (estimated size 384.0 B, free 366.1 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added rdd_114_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.2 MB)
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 28.0 (TID 42). 2285 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 42) in 9 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ShuffleMapStage 28 (sql at <unknown>:0) finished in 0.010 s
18/02/28 22:16:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:16:23 INFO DAGScheduler: running: Set()
18/02/28 22:16:23 INFO DAGScheduler: waiting: Set(ResultStage 29)
18/02/28 22:16:23 INFO DAGScheduler: failed: Set()
18/02/28 22:16:23 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[120] at sql at <unknown>:0), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.0 KB, free 366.1 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.1 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[120] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 43, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 29.0 (TID 43)
18/02/28 22:16:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:16:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 29.0 (TID 43). 1581 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 43) in 6 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ResultStage 29 (sql at <unknown>:0) finished in 0.006 s
18/02/28 22:16:23 INFO DAGScheduler: Job 20 finished: sql at <unknown>:0, took 0.024774 s
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:16:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:16:23 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:211)
18/02/28 22:16:23 INFO DAGScheduler: Got job 21 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:16:23 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:211)
18/02/28 22:16:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
18/02/28 22:16:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
18/02/28 22:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[123] at collect at utils.scala:211), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.6 KB, free 366.0 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.4 KB, free 366.0 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:63737 (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[123] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 30.0 (TID 44)
18/02/28 22:16:23 INFO BlockManager: Found block rdd_114_0 locally
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 30.0 (TID 44). 1690 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ShuffleMapStage 30 (collect at utils.scala:211) finished in 0.006 s
18/02/28 22:16:23 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:16:23 INFO DAGScheduler: running: Set()
18/02/28 22:16:23 INFO DAGScheduler: waiting: Set(ResultStage 31)
18/02/28 22:16:23 INFO DAGScheduler: failed: Set()
18/02/28 22:16:23 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[126] at collect at utils.scala:211), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.0 KB, free 366.0 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[126] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 31.0 (TID 45)
18/02/28 22:16:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:16:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 31.0 (TID 45). 1581 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 45) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:16:23 INFO DAGScheduler: Job 21 finished: collect at utils.scala:211, took 0.019417 s
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz11`
WHERE (0 = 1)
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d27a58b2e
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d27a58b2e` AS `zzz12`
WHERE (0 = 1)
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d27a58b2e`
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d30acee97
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d30acee97` AS `zzz13`
WHERE (0 = 1)
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_1669d30acee97`
18/02/28 22:16:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:16:23 INFO DAGScheduler: Got job 22 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:16:23 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:211)
18/02/28 22:16:23 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:16:23 INFO DAGScheduler: Missing parents: List()
18/02/28 22:16:23 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[129] at collect at utils.scala:211), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 19.8 KB, free 366.0 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.0 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:63737 (size: 9.2 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[129] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 32.0 (TID 46)
18/02/28 22:16:23 INFO BlockManager: Found block rdd_114_0 locally
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 32.0 (TID 46). 1359 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:16:23 INFO DAGScheduler: Job 22 finished: collect at utils.scala:211, took 0.008715 s
18/02/28 22:16:23 INFO CodeGenerator: Code generated in 9.559912 ms
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:16:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:16:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:16:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:16:23 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:16:23 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:16:23 INFO DAGScheduler: Got job 23 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:16:23 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:211)
18/02/28 22:16:23 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:16:23 INFO DAGScheduler: Missing parents: List()
18/02/28 22:16:23 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[131] at collect at utils.scala:211), which has no missing parents
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 10.3 KB, free 366.0 MB)
18/02/28 22:16:23 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.4 KB, free 366.0 MB)
18/02/28 22:16:23 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:16:23 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
18/02/28 22:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[131] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:16:23 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
18/02/28 22:16:23 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:16:23 INFO Executor: Running task 0.0 in stage 33.0 (TID 47)
18/02/28 22:16:23 INFO BlockManager: Found block rdd_114_0 locally
18/02/28 22:16:23 INFO Executor: Finished task 0.0 in stage 33.0 (TID 47). 1232 bytes result sent to driver
18/02/28 22:16:23 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 47) in 2 ms on localhost (executor driver) (1/1)
18/02/28 22:16:23 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/02/28 22:16:23 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:211) finished in 0.003 s
18/02/28 22:16:23 INFO DAGScheduler: Job 23 finished: collect at utils.scala:211, took 0.008665 s
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:17:59 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:17:59 INFO DAGScheduler: Got job 24 (collect at utils.scala:58) with 8 output partitions
18/02/28 22:17:59 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:58)
18/02/28 22:17:59 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:17:59 INFO DAGScheduler: Missing parents: List()
18/02/28 22:17:59 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[136] at map at utils.scala:55), which has no missing parents
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.2 KB, free 366.0 MB)
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.0 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:17:59 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
18/02/28 22:17:59 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 34 (MapPartitionsRDD[136] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/02/28 22:17:59 INFO TaskSchedulerImpl: Adding task set 34.0 with 8 tasks
18/02/28 22:17:59 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 49, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 50, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 51, localhost, executor driver, partition 3, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 4.0 in stage 34.0 (TID 52, localhost, executor driver, partition 4, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 5.0 in stage 34.0 (TID 53, localhost, executor driver, partition 5, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 6.0 in stage 34.0 (TID 54, localhost, executor driver, partition 6, PROCESS_LOCAL, 5035 bytes)
18/02/28 22:17:59 INFO TaskSetManager: Starting task 7.0 in stage 34.0 (TID 55, localhost, executor driver, partition 7, PROCESS_LOCAL, 5076 bytes)
18/02/28 22:17:59 INFO Executor: Running task 0.0 in stage 34.0 (TID 48)
18/02/28 22:17:59 INFO Executor: Running task 1.0 in stage 34.0 (TID 49)
18/02/28 22:17:59 INFO Executor: Running task 2.0 in stage 34.0 (TID 50)
18/02/28 22:17:59 INFO Executor: Running task 3.0 in stage 34.0 (TID 51)
18/02/28 22:17:59 INFO Executor: Running task 6.0 in stage 34.0 (TID 54)
18/02/28 22:17:59 INFO Executor: Running task 4.0 in stage 34.0 (TID 52)
18/02/28 22:17:59 INFO Executor: Running task 5.0 in stage 34.0 (TID 53)
18/02/28 22:17:59 INFO Executor: Running task 7.0 in stage 34.0 (TID 55)
18/02/28 22:17:59 INFO Executor: Finished task 1.0 in stage 34.0 (TID 49). 999 bytes result sent to driver
18/02/28 22:17:59 INFO Executor: Finished task 2.0 in stage 34.0 (TID 50). 999 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 49) in 6 ms on localhost (executor driver) (1/8)
18/02/28 22:17:59 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 50) in 6 ms on localhost (executor driver) (2/8)
18/02/28 22:17:59 INFO Executor: Finished task 4.0 in stage 34.0 (TID 52). 999 bytes result sent to driver
18/02/28 22:17:59 INFO Executor: Finished task 6.0 in stage 34.0 (TID 54). 999 bytes result sent to driver
18/02/28 22:17:59 INFO Executor: Finished task 3.0 in stage 34.0 (TID 51). 999 bytes result sent to driver
18/02/28 22:17:59 INFO Executor: Finished task 7.0 in stage 34.0 (TID 55). 963 bytes result sent to driver
18/02/28 22:17:59 INFO Executor: Finished task 0.0 in stage 34.0 (TID 48). 999 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 4.0 in stage 34.0 (TID 52) in 6 ms on localhost (executor driver) (3/8)
18/02/28 22:17:59 INFO Executor: Finished task 5.0 in stage 34.0 (TID 53). 999 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 51) in 7 ms on localhost (executor driver) (4/8)
18/02/28 22:17:59 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 48) in 9 ms on localhost (executor driver) (5/8)
18/02/28 22:17:59 INFO TaskSetManager: Finished task 6.0 in stage 34.0 (TID 54) in 8 ms on localhost (executor driver) (6/8)
18/02/28 22:17:59 INFO TaskSetManager: Finished task 7.0 in stage 34.0 (TID 55) in 8 ms on localhost (executor driver) (7/8)
18/02/28 22:17:59 INFO TaskSetManager: Finished task 5.0 in stage 34.0 (TID 53) in 8 ms on localhost (executor driver) (8/8)
18/02/28 22:17:59 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/02/28 22:17:59 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:58) finished in 0.009 s
18/02/28 22:17:59 INFO DAGScheduler: Job 24 finished: collect at utils.scala:58, took 0.013609 s
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO MapPartitionsRDD: Removing RDD 114 from persistence list
18/02/28 22:17:59 INFO BlockManager: Removing RDD 114
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: test
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:17:59 INFO SparkContext: Starting job: sql at <unknown>:0
18/02/28 22:17:59 INFO DAGScheduler: Registering RDD 144 (sql at <unknown>:0)
18/02/28 22:17:59 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
18/02/28 22:17:59 INFO DAGScheduler: Final stage: ResultStage 36 (sql at <unknown>:0)
18/02/28 22:17:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
18/02/28 22:17:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
18/02/28 22:17:59 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[144] at sql at <unknown>:0), which has no missing parents
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 14.6 KB, free 366.0 MB)
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.4 KB, free 366.0 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:63737 (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:17:59 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
18/02/28 22:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[144] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:17:59 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
18/02/28 22:17:59 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:17:59 INFO Executor: Running task 0.0 in stage 35.0 (TID 56)
18/02/28 22:17:59 INFO MemoryStore: Block rdd_141_0 stored as values in memory (estimated size 384.0 B, free 366.0 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added rdd_141_0 in memory on 127.0.0.1:63737 (size: 384.0 B, free: 366.2 MB)
18/02/28 22:17:59 INFO Executor: Finished task 0.0 in stage 35.0 (TID 56). 2285 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 56) in 8 ms on localhost (executor driver) (1/1)
18/02/28 22:17:59 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/02/28 22:17:59 INFO DAGScheduler: ShuffleMapStage 35 (sql at <unknown>:0) finished in 0.008 s
18/02/28 22:17:59 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:17:59 INFO DAGScheduler: running: Set()
18/02/28 22:17:59 INFO DAGScheduler: waiting: Set(ResultStage 36)
18/02/28 22:17:59 INFO DAGScheduler: failed: Set()
18/02/28 22:17:59 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[147] at sql at <unknown>:0), which has no missing parents
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:17:59 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
18/02/28 22:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[147] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:17:59 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
18/02/28 22:17:59 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:17:59 INFO Executor: Running task 0.0 in stage 36.0 (TID 57)
18/02/28 22:17:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:17:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:17:59 INFO Executor: Finished task 0.0 in stage 36.0 (TID 57). 1581 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:17:59 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/02/28 22:17:59 INFO DAGScheduler: ResultStage 36 (sql at <unknown>:0) finished in 0.004 s
18/02/28 22:17:59 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 0.021960 s
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:17:59 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:17:59 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:211)
18/02/28 22:17:59 INFO DAGScheduler: Got job 26 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:17:59 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:211)
18/02/28 22:17:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
18/02/28 22:17:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
18/02/28 22:17:59 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[150] at collect at utils.scala:211), which has no missing parents
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 14.6 KB, free 365.9 MB)
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 7.4 KB, free 365.9 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:63737 (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:17:59 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
18/02/28 22:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[150] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:17:59 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
18/02/28 22:17:59 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:17:59 INFO Executor: Running task 0.0 in stage 37.0 (TID 58)
18/02/28 22:17:59 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:17:59 INFO Executor: Finished task 0.0 in stage 37.0 (TID 58). 1690 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 58) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:17:59 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/02/28 22:17:59 INFO DAGScheduler: ShuffleMapStage 37 (collect at utils.scala:211) finished in 0.005 s
18/02/28 22:17:59 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:17:59 INFO DAGScheduler: running: Set()
18/02/28 22:17:59 INFO DAGScheduler: waiting: Set(ResultStage 38)
18/02/28 22:17:59 INFO DAGScheduler: failed: Set()
18/02/28 22:17:59 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[153] at collect at utils.scala:211), which has no missing parents
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
18/02/28 22:17:59 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
18/02/28 22:17:59 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:63737 (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:17:59 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
18/02/28 22:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[153] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:17:59 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
18/02/28 22:17:59 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 59, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:17:59 INFO Executor: Running task 0.0 in stage 38.0 (TID 59)
18/02/28 22:17:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:17:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:17:59 INFO Executor: Finished task 0.0 in stage 38.0 (TID 59). 1538 bytes result sent to driver
18/02/28 22:17:59 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 59) in 3 ms on localhost (executor driver) (1/1)
18/02/28 22:17:59 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/02/28 22:17:59 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:17:59 INFO DAGScheduler: Job 26 finished: collect at utils.scala:211, took 0.018005 s
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz14`
WHERE (0 = 1)
18/02/28 22:17:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:17:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:17:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:17:59 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:18:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:18:00 INFO SparkSqlParser: Parsing command: SELECT * FROM test LIMIT 5
18/02/28 22:18:00 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:18:00 INFO DAGScheduler: Got job 27 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:18:00 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:211)
18/02/28 22:18:00 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:18:00 INFO DAGScheduler: Missing parents: List()
18/02/28 22:18:00 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[155] at collect at utils.scala:211), which has no missing parents
18/02/28 22:18:00 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 10.3 KB, free 365.9 MB)
18/02/28 22:18:00 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.4 KB, free 365.9 MB)
18/02/28 22:18:00 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:63737 (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:18:00 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
18/02/28 22:18:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[155] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:18:00 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
18/02/28 22:18:00 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:18:00 INFO Executor: Running task 0.0 in stage 39.0 (TID 60)
18/02/28 22:18:00 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:18:00 INFO Executor: Finished task 0.0 in stage 39.0 (TID 60). 1232 bytes result sent to driver
18/02/28 22:18:00 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 60) in 4 ms on localhost (executor driver) (1/1)
18/02/28 22:18:00 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/02/28 22:18:00 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:211) finished in 0.004 s
18/02/28 22:18:00 INFO DAGScheduler: Job 27 finished: collect at utils.scala:211, took 0.009639 s
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:63737 in memory (size: 3.6 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned shuffle 10
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:63737 in memory (size: 9.2 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 825
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:63737 in memory (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 632
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:63737 in memory (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 627
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 628
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 637
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 833
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:63737 in memory (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1034
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1035
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 837
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 634
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:63737 in memory (size: 7.4 KB, free: 366.2 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 886
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 832
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:63737 in memory (size: 7.4 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned shuffle 6
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1027
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1030
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 835
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 829
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 798
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 828
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 636
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1026
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 631
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 830
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1028
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1037
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1025
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:63737 in memory (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 686
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:63737 in memory (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1032
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 635
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 626
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 633
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 629
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:63737 in memory (size: 5.4 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 827
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1036
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 834
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 598
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1086
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 826
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:63737 in memory (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 831
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 625
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1033
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 998
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 630
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1031
18/02/28 22:22:18 INFO ContextCleaner: Cleaned shuffle 8
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 836
18/02/28 22:22:18 INFO ContextCleaner: Cleaned accumulator 1029
18/02/28 22:22:18 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:63737 in memory (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:22:21 INFO SparkContext: Running Spark version 2.2.0
18/02/28 22:22:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 22:22:21 INFO SparkContext: Submitted application: sparklyr
18/02/28 22:22:21 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 22:22:21 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 22:22:21 INFO SecurityManager: Changing view acls groups to: 
18/02/28 22:22:21 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 22:22:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 22:22:21 INFO Utils: Successfully started service 'sparkDriver' on port 64111.
18/02/28 22:22:21 INFO SparkEnv: Registering MapOutputTracker
18/02/28 22:22:21 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 22:22:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 22:22:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 22:22:21 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-be8743e9-ed8f-4d62-a435-9647e7d51f6d
18/02/28 22:22:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 22:22:21 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 22:22:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/02/28 22:22:22 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/02/28 22:22:22 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/02/28 22:22:22 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:64111/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852942107
18/02/28 22:22:22 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:64111/jars/sparklyr-2.2-2.11.jar with timestamp 1519852942108
18/02/28 22:22:22 INFO Executor: Starting executor ID driver on host localhost
18/02/28 22:22:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64112.
18/02/28 22:22:22 INFO NettyBlockTransferService: Server created on 127.0.0.1:64112
18/02/28 22:22:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 22:22:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64112, None)
18/02/28 22:22:22 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64112 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64112, None)
18/02/28 22:22:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64112, None)
18/02/28 22:22:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64112, None)
18/02/28 22:22:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 22:22:22 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 22:22:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 22:22:22 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 22:22:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 22:22:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 22:22:23 INFO ObjectStore: ObjectStore, initialize called
18/02/28 22:22:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 22:22:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 22:22:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 22:22:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:22:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:22:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:22:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:22:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 22:22:26 INFO ObjectStore: Initialized ObjectStore
18/02/28 22:22:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 22:22:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 22:22:26 INFO HiveMetaStore: Added admin role in metastore
18/02/28 22:22:26 INFO HiveMetaStore: Added public role in metastore
18/02/28 22:22:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 22:22:26 INFO HiveMetaStore: 0: get_all_databases
18/02/28 22:22:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 22:22:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 22:22:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 22:22:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 22:22:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/d62fa708-1e79-452a-a087-eea13744c46e_resources
18/02/28 22:22:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/d62fa708-1e79-452a-a087-eea13744c46e
18/02/28 22:22:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/d62fa708-1e79-452a-a087-eea13744c46e
18/02/28 22:22:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/d62fa708-1e79-452a-a087-eea13744c46e/_tmp_space.db
18/02/28 22:22:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:22:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:22:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:22:26 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 22:22:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 22:22:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 22:22:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/dbd5b6d8-0257-4201-894e-8f1bd68aac48_resources
18/02/28 22:22:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/dbd5b6d8-0257-4201-894e-8f1bd68aac48
18/02/28 22:22:26 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/dbd5b6d8-0257-4201-894e-8f1bd68aac48
18/02/28 22:22:26 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/dbd5b6d8-0257-4201-894e-8f1bd68aac48/_tmp_space.db
18/02/28 22:22:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 22:22:26 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 22:22:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 22:22:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:22:28 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:22:28 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:22:28 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:22:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 22:22:28 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 22:22:28 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 22:22:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 22:22:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 22:22:28 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:22:28 INFO DAGScheduler: Missing parents: List()
18/02/28 22:22:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 22:22:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 22:22:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 22:22:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64112 (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:22:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 22:22:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:22:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 22:22:28 INFO Executor: Fetching spark://127.0.0.1:64111/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519852942107
18/02/28 22:22:28 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64111 after 11 ms (0 ms spent in bootstraps)
18/02/28 22:22:28 INFO Utils: Fetching spark://127.0.0.1:64111/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-689ea3c8-93ca-473f-a779-e6bb5a95e912/userFiles-31846f82-55b9-4e6c-8707-b94d7a84984f/fetchFileTemp8080344262569630065.tmp
18/02/28 22:22:28 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-689ea3c8-93ca-473f-a779-e6bb5a95e912/userFiles-31846f82-55b9-4e6c-8707-b94d7a84984f/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 22:22:28 INFO Executor: Fetching spark://127.0.0.1:64111/jars/sparklyr-2.2-2.11.jar with timestamp 1519852942108
18/02/28 22:22:28 INFO Utils: Fetching spark://127.0.0.1:64111/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-689ea3c8-93ca-473f-a779-e6bb5a95e912/userFiles-31846f82-55b9-4e6c-8707-b94d7a84984f/fetchFileTemp5664118373811658841.tmp
18/02/28 22:22:28 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-689ea3c8-93ca-473f-a779-e6bb5a95e912/userFiles-31846f82-55b9-4e6c-8707-b94d7a84984f/sparklyr-2.2-2.11.jar to class loader
18/02/28 22:22:28 INFO CodeGenerator: Code generated in 162.57762 ms
18/02/28 22:22:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 22:22:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 406 ms on localhost (executor driver) (1/1)
18/02/28 22:22:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 22:22:29 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.421 s
18/02/28 22:22:29 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.556588 s
18/02/28 22:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: test
18/02/28 22:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: `test`
18/02/28 22:22:29 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 22:22:29 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 22:22:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64112 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 110.502359 ms
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 9.147392 ms
18/02/28 22:22:29 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 22:22:29 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:22:29 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 22:22:29 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 22:22:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 22:22:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 22:22:29 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 22:22:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64112 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:22:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 22:22:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:22:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 8.236739 ms
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 16.95517 ms
18/02/28 22:22:29 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 22:22:29 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:64112 (size: 384.0 B, free: 366.3 MB)
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 3.805442 ms
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 16.512156 ms
18/02/28 22:22:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 22:22:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 137 ms on localhost (executor driver) (1/1)
18/02/28 22:22:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 22:22:29 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.138 s
18/02/28 22:22:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:22:29 INFO DAGScheduler: running: Set()
18/02/28 22:22:29 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 22:22:29 INFO DAGScheduler: failed: Set()
18/02/28 22:22:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 22:22:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64112 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 22:22:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:22:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 22:22:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 22:22:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
18/02/28 22:22:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
18/02/28 22:22:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 22:22:29 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
18/02/28 22:22:29 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.212471 s
18/02/28 22:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 22:22:29 INFO HiveMetaStore: 0: get_database: default
18/02/28 22:22:29 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 22:22:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:22:29 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 22:22:29 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:22:29 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 22:22:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 22:22:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 22:22:29 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 22:22:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64112 (size: 7.3 KB, free: 366.3 MB)
18/02/28 22:22:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 22:22:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:22:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 22:22:29 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:22:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 22:22:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
18/02/28 22:22:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 22:22:29 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.014 s
18/02/28 22:22:29 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:22:29 INFO DAGScheduler: running: Set()
18/02/28 22:22:29 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 22:22:29 INFO DAGScheduler: failed: Set()
18/02/28 22:22:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 22:22:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 22:22:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64112 (size: 3.7 KB, free: 366.3 MB)
18/02/28 22:22:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 22:22:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 22:22:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 22:22:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:22:29 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
18/02/28 22:22:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
18/02/28 22:22:29 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 22:22:29 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.006 s
18/02/28 22:22:29 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.039017 s
18/02/28 22:22:29 INFO CodeGenerator: Code generated in 5.585104 ms
18/02/28 22:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 22:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:22:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_16bc1166f674b
18/02/28 22:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_16bc1166f674b` AS `zzz2`
WHERE (0 = 1)
18/02/28 22:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_16bc1166f674b`
18/02/28 22:22:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_16bc16565b19c
18/02/28 22:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_16bc16565b19c` AS `zzz3`
WHERE (0 = 1)
18/02/28 22:22:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:22:30 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_16bc16565b19c`
18/02/28 22:22:30 INFO CodeGenerator: Code generated in 22.282885 ms
18/02/28 22:22:30 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:22:30 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:22:30 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 22:22:30 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:22:30 INFO DAGScheduler: Missing parents: List()
18/02/28 22:22:30 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 22:22:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 22:22:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 22:22:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64112 (size: 9.2 KB, free: 366.3 MB)
18/02/28 22:22:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 22:22:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:22:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 22:22:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:22:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 22:22:30 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 22:22:30 INFO CodeGenerator: Code generated in 14.130089 ms
18/02/28 22:22:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 22:22:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (executor driver) (1/1)
18/02/28 22:22:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 22:22:30 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.033 s
18/02/28 22:22:30 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.040004 s
18/02/28 22:22:30 INFO CodeGenerator: Code generated in 13.53552 ms
18/02/28 22:22:31 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 22:22:31 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/02/28 22:22:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 22:22:31 INFO MemoryStore: MemoryStore cleared
18/02/28 22:22:31 INFO BlockManager: BlockManager stopped
18/02/28 22:22:31 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 22:22:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 22:22:31 INFO SparkContext: Successfully stopped SparkContext
18/02/28 22:22:31 INFO ShutdownHookManager: Shutdown hook called
18/02/28 22:22:31 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-689ea3c8-93ca-473f-a779-e6bb5a95e912
18/02/28 22:27:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:27:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:27:33 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
18/02/28 22:27:33 INFO DAGScheduler: Registering RDD 161 (flatMap at CountVectorizer.scala:163)
18/02/28 22:27:33 INFO DAGScheduler: Got job 28 (count at CountVectorizer.scala:176) with 1 output partitions
18/02/28 22:27:33 INFO DAGScheduler: Final stage: ResultStage 41 (count at CountVectorizer.scala:176)
18/02/28 22:27:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
18/02/28 22:27:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
18/02/28 22:27:33 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[161] at flatMap at CountVectorizer.scala:163), which has no missing parents
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 23.2 KB, free 366.3 MB)
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 11.1 KB, free 366.3 MB)
18/02/28 22:27:33 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:63737 (size: 11.1 KB, free: 366.3 MB)
18/02/28 22:27:33 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[161] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/02/28 22:27:33 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:27:33 INFO Executor: Running task 0.0 in stage 40.0 (TID 61)
18/02/28 22:27:33 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:27:33 INFO CodeGenerator: Code generated in 9.781768 ms
18/02/28 22:27:33 INFO Executor: Finished task 0.0 in stage 40.0 (TID 61). 1568 bytes result sent to driver
18/02/28 22:27:33 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 61) in 40 ms on localhost (executor driver) (1/1)
18/02/28 22:27:33 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/02/28 22:27:33 INFO DAGScheduler: ShuffleMapStage 40 (flatMap at CountVectorizer.scala:163) finished in 0.040 s
18/02/28 22:27:33 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:27:33 INFO DAGScheduler: running: Set()
18/02/28 22:27:33 INFO DAGScheduler: waiting: Set(ResultStage 41)
18/02/28 22:27:33 INFO DAGScheduler: failed: Set()
18/02/28 22:27:33 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[164] at map at CountVectorizer.scala:173), which has no missing parents
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 3.2 KB, free 366.3 MB)
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1887.0 B, free 366.3 MB)
18/02/28 22:27:33 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:63737 (size: 1887.0 B, free: 366.3 MB)
18/02/28 22:27:33 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[164] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:33 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
18/02/28 22:27:33 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 62, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 22:27:33 INFO Executor: Running task 0.0 in stage 41.0 (TID 62)
18/02/28 22:27:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:27:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 22:27:33 INFO MemoryStore: Block rdd_164_0 stored as values in memory (estimated size 280.0 B, free 366.3 MB)
18/02/28 22:27:33 INFO BlockManagerInfo: Added rdd_164_0 in memory on 127.0.0.1:63737 (size: 280.0 B, free: 366.3 MB)
18/02/28 22:27:33 INFO Executor: Finished task 0.0 in stage 41.0 (TID 62). 1830 bytes result sent to driver
18/02/28 22:27:33 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 62) in 18 ms on localhost (executor driver) (1/1)
18/02/28 22:27:33 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/02/28 22:27:33 INFO DAGScheduler: ResultStage 41 (count at CountVectorizer.scala:176) finished in 0.018 s
18/02/28 22:27:33 INFO DAGScheduler: Job 28 finished: count at CountVectorizer.scala:176, took 0.081581 s
18/02/28 22:27:33 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
18/02/28 22:27:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 143 bytes
18/02/28 22:27:33 INFO DAGScheduler: Got job 29 (top at CountVectorizer.scala:179) with 1 output partitions
18/02/28 22:27:33 INFO DAGScheduler: Final stage: ResultStage 43 (top at CountVectorizer.scala:179)
18/02/28 22:27:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
18/02/28 22:27:33 INFO DAGScheduler: Missing parents: List()
18/02/28 22:27:33 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[165] at top at CountVectorizer.scala:179), which has no missing parents
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 4.2 KB, free 366.3 MB)
18/02/28 22:27:33 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.3 MB)
18/02/28 22:27:33 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:63737 (size: 2.2 KB, free: 366.3 MB)
18/02/28 22:27:33 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[165] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:33 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
18/02/28 22:27:33 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 22:27:33 INFO Executor: Running task 0.0 in stage 43.0 (TID 63)
18/02/28 22:27:33 INFO BlockManager: Found block rdd_164_0 locally
18/02/28 22:27:33 INFO Executor: Finished task 0.0 in stage 43.0 (TID 63). 1570 bytes result sent to driver
18/02/28 22:27:33 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 63) in 14 ms on localhost (executor driver) (1/1)
18/02/28 22:27:33 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/02/28 22:27:33 INFO DAGScheduler: ResultStage 43 (top at CountVectorizer.scala:179) finished in 0.014 s
18/02/28 22:27:33 INFO DAGScheduler: Job 29 finished: top at CountVectorizer.scala:179, took 0.025270 s
18/02/28 22:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:27:42 INFO SparkContext: Starting job: count at CountVectorizer.scala:176
18/02/28 22:27:42 INFO DAGScheduler: Registering RDD 171 (flatMap at CountVectorizer.scala:163)
18/02/28 22:27:42 INFO DAGScheduler: Got job 30 (count at CountVectorizer.scala:176) with 1 output partitions
18/02/28 22:27:42 INFO DAGScheduler: Final stage: ResultStage 45 (count at CountVectorizer.scala:176)
18/02/28 22:27:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/02/28 22:27:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/02/28 22:27:42 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[171] at flatMap at CountVectorizer.scala:163), which has no missing parents
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 23.2 KB, free 366.2 MB)
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 11.1 KB, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:63737 (size: 11.1 KB, free: 366.3 MB)
18/02/28 22:27:42 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[171] at flatMap at CountVectorizer.scala:163) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:42 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
18/02/28 22:27:42 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 22:27:42 INFO Executor: Running task 0.0 in stage 44.0 (TID 64)
18/02/28 22:27:42 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:27:42 INFO CodeGenerator: Code generated in 9.675082 ms
18/02/28 22:27:42 INFO Executor: Finished task 0.0 in stage 44.0 (TID 64). 1568 bytes result sent to driver
18/02/28 22:27:42 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 64) in 17 ms on localhost (executor driver) (1/1)
18/02/28 22:27:42 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/02/28 22:27:42 INFO DAGScheduler: ShuffleMapStage 44 (flatMap at CountVectorizer.scala:163) finished in 0.018 s
18/02/28 22:27:42 INFO DAGScheduler: looking for newly runnable stages
18/02/28 22:27:42 INFO DAGScheduler: running: Set()
18/02/28 22:27:42 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/02/28 22:27:42 INFO DAGScheduler: failed: Set()
18/02/28 22:27:42 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[174] at map at CountVectorizer.scala:173), which has no missing parents
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 3.2 KB, free 366.2 MB)
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1887.0 B, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:63737 (size: 1887.0 B, free: 366.3 MB)
18/02/28 22:27:42 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[174] at map at CountVectorizer.scala:173) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:42 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
18/02/28 22:27:42 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 65, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/02/28 22:27:42 INFO Executor: Running task 0.0 in stage 45.0 (TID 65)
18/02/28 22:27:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 22:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 22:27:42 INFO MemoryStore: Block rdd_174_0 stored as values in memory (estimated size 280.0 B, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added rdd_174_0 in memory on 127.0.0.1:63737 (size: 280.0 B, free: 366.3 MB)
18/02/28 22:27:42 INFO Executor: Finished task 0.0 in stage 45.0 (TID 65). 1787 bytes result sent to driver
18/02/28 22:27:42 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 65) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:27:42 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/02/28 22:27:42 INFO DAGScheduler: ResultStage 45 (count at CountVectorizer.scala:176) finished in 0.006 s
18/02/28 22:27:42 INFO DAGScheduler: Job 30 finished: count at CountVectorizer.scala:176, took 0.036266 s
18/02/28 22:27:42 INFO SparkContext: Starting job: top at CountVectorizer.scala:179
18/02/28 22:27:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 143 bytes
18/02/28 22:27:42 INFO DAGScheduler: Got job 31 (top at CountVectorizer.scala:179) with 1 output partitions
18/02/28 22:27:42 INFO DAGScheduler: Final stage: ResultStage 47 (top at CountVectorizer.scala:179)
18/02/28 22:27:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/02/28 22:27:42 INFO DAGScheduler: Missing parents: List()
18/02/28 22:27:42 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[175] at top at CountVectorizer.scala:179), which has no missing parents
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 4.2 KB, free 366.2 MB)
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:63737 (size: 2.2 KB, free: 366.3 MB)
18/02/28 22:27:42 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[175] at top at CountVectorizer.scala:179) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:42 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
18/02/28 22:27:42 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
18/02/28 22:27:42 INFO Executor: Running task 0.0 in stage 47.0 (TID 66)
18/02/28 22:27:42 INFO BlockManager: Found block rdd_174_0 locally
18/02/28 22:27:42 INFO Executor: Finished task 0.0 in stage 47.0 (TID 66). 1484 bytes result sent to driver
18/02/28 22:27:42 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 66) in 2 ms on localhost (executor driver) (1/1)
18/02/28 22:27:42 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/02/28 22:27:42 INFO DAGScheduler: ResultStage 47 (top at CountVectorizer.scala:179) finished in 0.002 s
18/02/28 22:27:42 INFO DAGScheduler: Job 31 finished: top at CountVectorizer.scala:179, took 0.007721 s
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 264.0 B, free 366.2 MB)
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 276.0 B, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:63737 (size: 276.0 B, free: 366.3 MB)
18/02/28 22:27:42 INFO SparkContext: Created broadcast 46 from broadcast at CountVectorizer.scala:244
18/02/28 22:27:42 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d3e1eec8
18/02/28 22:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d3e1eec8` AS `zzz15`
WHERE (0 = 1)
18/02/28 22:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d3e1eec8`
18/02/28 22:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d3e1eec8`
LIMIT 10
18/02/28 22:27:42 INFO CodeGenerator: Code generated in 21.837775 ms
18/02/28 22:27:42 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:27:42 INFO DAGScheduler: Got job 32 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:27:42 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:211)
18/02/28 22:27:42 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:27:42 INFO DAGScheduler: Missing parents: List()
18/02/28 22:27:42 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[178] at collect at utils.scala:211), which has no missing parents
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 35.5 KB, free 366.2 MB)
18/02/28 22:27:42 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 14.0 KB, free 366.2 MB)
18/02/28 22:27:42 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:63737 (size: 14.0 KB, free: 366.3 MB)
18/02/28 22:27:42 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
18/02/28 22:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[178] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:27:42 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/02/28 22:27:42 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:27:42 INFO Executor: Running task 0.0 in stage 48.0 (TID 67)
18/02/28 22:27:42 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:27:42 INFO Executor: Finished task 0.0 in stage 48.0 (TID 67). 1493 bytes result sent to driver
18/02/28 22:27:42 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 67) in 19 ms on localhost (executor driver) (1/1)
18/02/28 22:27:42 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/02/28 22:27:42 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:211) finished in 0.020 s
18/02/28 22:27:42 INFO DAGScheduler: Job 32 finished: collect at utils.scala:211, took 0.024261 s
18/02/28 22:27:42 INFO CodeGenerator: Code generated in 12.085972 ms
18/02/28 22:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 22:30:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1669d732b2b19
18/02/28 22:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d732b2b19` AS `zzz16`
WHERE (0 = 1)
18/02/28 22:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d732b2b19`
18/02/28 22:30:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 22:30:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1669d732b2b19`
LIMIT 10
18/02/28 22:30:19 INFO CodeGenerator: Code generated in 11.33374 ms
18/02/28 22:30:19 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 22:30:19 INFO DAGScheduler: Got job 33 (collect at utils.scala:211) with 1 output partitions
18/02/28 22:30:19 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:211)
18/02/28 22:30:19 INFO DAGScheduler: Parents of final stage: List()
18/02/28 22:30:19 INFO DAGScheduler: Missing parents: List()
18/02/28 22:30:19 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[181] at collect at utils.scala:211), which has no missing parents
18/02/28 22:30:19 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 366.1 MB)
18/02/28 22:30:19 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.2 KB, free 366.1 MB)
18/02/28 22:30:19 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:63737 (size: 8.2 KB, free: 366.2 MB)
18/02/28 22:30:19 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
18/02/28 22:30:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[181] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 22:30:19 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
18/02/28 22:30:19 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 22:30:19 INFO Executor: Running task 0.0 in stage 49.0 (TID 68)
18/02/28 22:30:19 INFO BlockManager: Found block rdd_141_0 locally
18/02/28 22:30:19 INFO Executor: Finished task 0.0 in stage 49.0 (TID 68). 1411 bytes result sent to driver
18/02/28 22:30:19 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 68) in 5 ms on localhost (executor driver) (1/1)
18/02/28 22:30:19 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/02/28 22:30:19 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:211) finished in 0.005 s
18/02/28 22:30:19 INFO DAGScheduler: Job 33 finished: collect at utils.scala:211, took 0.010460 s
18/02/28 22:30:19 INFO CodeGenerator: Code generated in 8.000595 ms
18/02/28 22:44:22 INFO ContextCleaner: Cleaned shuffle 0
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:63737 in memory (size: 14.0 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 1246
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:63737 in memory (size: 1887.0 B, free: 366.3 MB)
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 1173
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:63737 in memory (size: 2.2 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:63737 in memory (size: 2.2 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 1172
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:63737 in memory (size: 11.1 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO BlockManager: Removing RDD 164
18/02/28 22:44:22 INFO ContextCleaner: Cleaned RDD 164
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:63737 in memory (size: 11.1 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:63737 in memory (size: 8.2 KB, free: 366.3 MB)
18/02/28 22:44:22 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:63737 in memory (size: 1887.0 B, free: 366.3 MB)
18/02/28 22:44:22 INFO ContextCleaner: Cleaned shuffle 13
18/02/28 22:44:22 INFO ContextCleaner: Cleaned shuffle 12
18/02/28 22:44:22 INFO BlockManager: Removing RDD 174
18/02/28 22:44:22 INFO ContextCleaner: Cleaned RDD 174
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 1247
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 54
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 61
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 63
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 55
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 56
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 52
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 59
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 60
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 62
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 58
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 57
18/02/28 22:44:22 INFO ContextCleaner: Cleaned accumulator 53
18/02/28 22:44:39 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 22:44:39 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 22:44:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 22:44:39 INFO MemoryStore: MemoryStore cleared
18/02/28 22:44:39 INFO BlockManager: BlockManager stopped
18/02/28 22:44:39 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 22:44:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 22:44:39 INFO SparkContext: Successfully stopped SparkContext
18/02/28 22:44:39 INFO ShutdownHookManager: Shutdown hook called
18/02/28 22:44:39 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-bd02c915-541a-4b3d-8a1c-bc106a674100
18/02/28 23:20:53 INFO SparkContext: Running Spark version 2.2.0
18/02/28 23:20:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 23:20:53 INFO SparkContext: Submitted application: sparklyr
18/02/28 23:20:53 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 23:20:53 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 23:20:53 INFO SecurityManager: Changing view acls groups to: 
18/02/28 23:20:53 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 23:20:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 23:20:53 INFO Utils: Successfully started service 'sparkDriver' on port 49466.
18/02/28 23:20:53 INFO SparkEnv: Registering MapOutputTracker
18/02/28 23:20:53 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 23:20:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 23:20:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 23:20:53 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-90a120fa-7746-4c1e-8f2e-463db8c5b5f5
18/02/28 23:20:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 23:20:54 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 23:20:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 23:20:54 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 23:20:54 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:49466/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856454224
18/02/28 23:20:54 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:49466/jars/sparklyr-2.2-2.11.jar with timestamp 1519856454225
18/02/28 23:20:54 INFO Executor: Starting executor ID driver on host localhost
18/02/28 23:20:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49467.
18/02/28 23:20:54 INFO NettyBlockTransferService: Server created on 127.0.0.1:49467
18/02/28 23:20:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 23:20:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49467, None)
18/02/28 23:20:54 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49467 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49467, None)
18/02/28 23:20:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49467, None)
18/02/28 23:20:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49467, None)
18/02/28 23:20:54 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 23:20:54 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 23:20:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 23:20:54 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 23:20:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 23:20:55 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 23:20:55 INFO ObjectStore: ObjectStore, initialize called
18/02/28 23:20:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 23:20:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 23:20:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 23:20:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:20:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:20:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:20:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:20:58 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 23:20:58 INFO ObjectStore: Initialized ObjectStore
18/02/28 23:20:58 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 23:20:58 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 23:20:58 INFO HiveMetaStore: Added admin role in metastore
18/02/28 23:20:58 INFO HiveMetaStore: Added public role in metastore
18/02/28 23:20:58 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 23:20:58 INFO HiveMetaStore: 0: get_all_databases
18/02/28 23:20:58 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 23:20:58 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 23:20:58 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 23:20:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:20:58 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/a7c96ba5-4289-40fa-9396-a24e830db516_resources
18/02/28 23:20:58 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/a7c96ba5-4289-40fa-9396-a24e830db516
18/02/28 23:20:58 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/a7c96ba5-4289-40fa-9396-a24e830db516
18/02/28 23:20:58 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/a7c96ba5-4289-40fa-9396-a24e830db516/_tmp_space.db
18/02/28 23:20:58 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:20:58 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:20:58 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:20:58 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 23:20:58 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 23:20:58 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 23:20:58 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/7d507870-9b50-4ff8-84fe-5f2a637503b2_resources
18/02/28 23:20:58 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/7d507870-9b50-4ff8-84fe-5f2a637503b2
18/02/28 23:20:58 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/7d507870-9b50-4ff8-84fe-5f2a637503b2
18/02/28 23:20:58 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/7d507870-9b50-4ff8-84fe-5f2a637503b2/_tmp_space.db
18/02/28 23:20:58 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:20:59 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 23:20:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 23:21:00 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:21:00 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:21:00 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:21:00 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:21:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 23:21:00 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 23:21:00 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 23:21:00 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 23:21:00 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 23:21:00 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:21:00 INFO DAGScheduler: Missing parents: List()
18/02/28 23:21:00 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 23:21:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 23:21:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 23:21:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49467 (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:21:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 23:21:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:21:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 23:21:00 INFO Executor: Fetching spark://127.0.0.1:49466/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856454224
18/02/28 23:21:00 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49466 after 12 ms (0 ms spent in bootstraps)
18/02/28 23:21:00 INFO Utils: Fetching spark://127.0.0.1:49466/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-8fbeac20-43a5-41b6-ae75-7673833ca8a3/userFiles-4cbb8854-bd6e-4153-bcbf-b1b0a05e1331/fetchFileTemp6417085510528323034.tmp
18/02/28 23:21:00 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-8fbeac20-43a5-41b6-ae75-7673833ca8a3/userFiles-4cbb8854-bd6e-4153-bcbf-b1b0a05e1331/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 23:21:00 INFO Executor: Fetching spark://127.0.0.1:49466/jars/sparklyr-2.2-2.11.jar with timestamp 1519856454225
18/02/28 23:21:00 INFO Utils: Fetching spark://127.0.0.1:49466/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-8fbeac20-43a5-41b6-ae75-7673833ca8a3/userFiles-4cbb8854-bd6e-4153-bcbf-b1b0a05e1331/fetchFileTemp6879076877204422352.tmp
18/02/28 23:21:00 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-8fbeac20-43a5-41b6-ae75-7673833ca8a3/userFiles-4cbb8854-bd6e-4153-bcbf-b1b0a05e1331/sparklyr-2.2-2.11.jar to class loader
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 171.166634 ms
18/02/28 23:21:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
18/02/28 23:21:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 429 ms on localhost (executor driver) (1/1)
18/02/28 23:21:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 23:21:01 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.449 s
18/02/28 23:21:01 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.603430 s
18/02/28 23:21:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:01 INFO SparkSqlParser: Parsing command: test
18/02/28 23:21:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:01 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 23:21:01 INFO SparkSqlParser: Parsing command: `test`
18/02/28 23:21:01 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 23:21:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49467 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:21:01 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 16.816222 ms
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 9.880071 ms
18/02/28 23:21:01 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 23:21:01 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:21:01 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 23:21:01 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:21:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 23:21:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 23:21:01 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:21:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:21:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 23:21:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49467 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:21:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 23:21:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:21:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 8.212131 ms
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 19.370596 ms
18/02/28 23:21:01 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 23:21:01 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:49467 (size: 384.0 B, free: 366.3 MB)
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 4.639292 ms
18/02/28 23:21:01 INFO CodeGenerator: Code generated in 15.492064 ms
18/02/28 23:21:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 23:21:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 144 ms on localhost (executor driver) (1/1)
18/02/28 23:21:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 23:21:01 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.146 s
18/02/28 23:21:01 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:21:01 INFO DAGScheduler: running: Set()
18/02/28 23:21:01 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 23:21:01 INFO DAGScheduler: failed: Set()
18/02/28 23:21:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:21:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 23:21:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 23:21:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49467 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:21:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 23:21:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:21:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 23:21:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:21:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/02/28 23:21:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
18/02/28 23:21:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (executor driver) (1/1)
18/02/28 23:21:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 23:21:02 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.035 s
18/02/28 23:21:02 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.224583 s
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 23:21:02 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:21:02 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:21:02 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:21:02 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 23:21:02 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:21:02 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 23:21:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 23:21:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 23:21:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 23:21:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49467 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:21:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 23:21:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:21:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 23:21:02 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:21:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 23:21:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
18/02/28 23:21:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 23:21:02 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.013 s
18/02/28 23:21:02 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:21:02 INFO DAGScheduler: running: Set()
18/02/28 23:21:02 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 23:21:02 INFO DAGScheduler: failed: Set()
18/02/28 23:21:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 23:21:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49467 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:21:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 23:21:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:21:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 23:21:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:21:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 23:21:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
18/02/28 23:21:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
18/02/28 23:21:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 23:21:02 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.006 s
18/02/28 23:21:02 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.034237 s
18/02/28 23:21:02 INFO CodeGenerator: Code generated in 6.843064 ms
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17e482a3bb807
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17e482a3bb807` AS `zzz2`
WHERE (0 = 1)
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17e482a3bb807`
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17e48392e165d
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17e48392e165d` AS `zzz3`
WHERE (0 = 1)
18/02/28 23:21:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:21:02 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_17e48392e165d`
18/02/28 23:21:02 INFO CodeGenerator: Code generated in 20.887907 ms
18/02/28 23:21:02 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:21:02 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:21:02 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 23:21:02 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:21:02 INFO DAGScheduler: Missing parents: List()
18/02/28 23:21:02 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 23:21:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 23:21:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49467 (size: 9.2 KB, free: 366.3 MB)
18/02/28 23:21:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 23:21:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:21:02 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 23:21:02 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:21:02 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 23:21:02 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:21:02 INFO CodeGenerator: Code generated in 15.093655 ms
18/02/28 23:21:02 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 23:21:02 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 36 ms on localhost (executor driver) (1/1)
18/02/28 23:21:02 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 23:21:02 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.037 s
18/02/28 23:21:02 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.045815 s
18/02/28 23:21:02 INFO CodeGenerator: Code generated in 13.398956 ms
18/02/28 23:21:03 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 23:21:03 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 23:21:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 23:21:03 INFO MemoryStore: MemoryStore cleared
18/02/28 23:21:03 INFO BlockManager: BlockManager stopped
18/02/28 23:21:03 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 23:21:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 23:21:03 INFO SparkContext: Successfully stopped SparkContext
18/02/28 23:21:03 INFO ShutdownHookManager: Shutdown hook called
18/02/28 23:21:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-8fbeac20-43a5-41b6-ae75-7673833ca8a3
18/02/28 23:22:18 INFO SparkContext: Running Spark version 2.2.0
18/02/28 23:22:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 23:22:18 INFO SparkContext: Submitted application: sparklyr
18/02/28 23:22:18 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 23:22:18 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 23:22:18 INFO SecurityManager: Changing view acls groups to: 
18/02/28 23:22:18 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 23:22:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 23:22:19 INFO Utils: Successfully started service 'sparkDriver' on port 49565.
18/02/28 23:22:19 INFO SparkEnv: Registering MapOutputTracker
18/02/28 23:22:19 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 23:22:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 23:22:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 23:22:19 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-28b7a0c1-a1c9-4a34-a1da-ed571a29900f
18/02/28 23:22:19 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 23:22:19 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 23:22:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 23:22:19 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 23:22:19 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:49565/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856539320
18/02/28 23:22:19 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:49565/jars/sparklyr-2.2-2.11.jar with timestamp 1519856539321
18/02/28 23:22:19 INFO Executor: Starting executor ID driver on host localhost
18/02/28 23:22:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49566.
18/02/28 23:22:19 INFO NettyBlockTransferService: Server created on 127.0.0.1:49566
18/02/28 23:22:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 23:22:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49566, None)
18/02/28 23:22:19 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49566 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49566, None)
18/02/28 23:22:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49566, None)
18/02/28 23:22:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49566, None)
18/02/28 23:22:19 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 23:22:19 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 23:22:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 23:22:19 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 23:22:20 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 23:22:20 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 23:22:20 INFO ObjectStore: ObjectStore, initialize called
18/02/28 23:22:20 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 23:22:20 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 23:22:21 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 23:22:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:22:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:22:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:22:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:22:23 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 23:22:23 INFO ObjectStore: Initialized ObjectStore
18/02/28 23:22:23 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 23:22:23 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 23:22:23 INFO HiveMetaStore: Added admin role in metastore
18/02/28 23:22:23 INFO HiveMetaStore: Added public role in metastore
18/02/28 23:22:23 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 23:22:23 INFO HiveMetaStore: 0: get_all_databases
18/02/28 23:22:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 23:22:23 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 23:22:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 23:22:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:22:23 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/21d2cfa6-a475-4534-a890-d3259d384937_resources
18/02/28 23:22:23 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/21d2cfa6-a475-4534-a890-d3259d384937
18/02/28 23:22:23 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/21d2cfa6-a475-4534-a890-d3259d384937
18/02/28 23:22:23 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/21d2cfa6-a475-4534-a890-d3259d384937/_tmp_space.db
18/02/28 23:22:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:22:23 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:22:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:22:23 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 23:22:23 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 23:22:23 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 23:22:23 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/776e5368-202b-480a-8fdd-b2278637097e_resources
18/02/28 23:22:23 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/776e5368-202b-480a-8fdd-b2278637097e
18/02/28 23:22:23 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/776e5368-202b-480a-8fdd-b2278637097e
18/02/28 23:22:23 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/776e5368-202b-480a-8fdd-b2278637097e/_tmp_space.db
18/02/28 23:22:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:22:23 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 23:22:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 23:22:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:22:25 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:22:25 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:22:25 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:22:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 23:22:25 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 23:22:25 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 23:22:25 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 23:22:25 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 23:22:25 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:22:25 INFO DAGScheduler: Missing parents: List()
18/02/28 23:22:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 23:22:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 23:22:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 23:22:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49566 (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:22:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 23:22:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:22:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 23:22:25 INFO Executor: Fetching spark://127.0.0.1:49565/jars/sparklyr-2.2-2.11.jar with timestamp 1519856539321
18/02/28 23:22:25 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49565 after 11 ms (0 ms spent in bootstraps)
18/02/28 23:22:25 INFO Utils: Fetching spark://127.0.0.1:49565/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-907ae66c-21f1-4d65-8dcf-98db153697ca/userFiles-e8e871ae-42e8-431d-9c6f-2fb331d63875/fetchFileTemp2241091946875012208.tmp
18/02/28 23:22:25 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-907ae66c-21f1-4d65-8dcf-98db153697ca/userFiles-e8e871ae-42e8-431d-9c6f-2fb331d63875/sparklyr-2.2-2.11.jar to class loader
18/02/28 23:22:25 INFO Executor: Fetching spark://127.0.0.1:49565/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856539320
18/02/28 23:22:25 INFO Utils: Fetching spark://127.0.0.1:49565/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-907ae66c-21f1-4d65-8dcf-98db153697ca/userFiles-e8e871ae-42e8-431d-9c6f-2fb331d63875/fetchFileTemp911534247735854192.tmp
18/02/28 23:22:25 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-907ae66c-21f1-4d65-8dcf-98db153697ca/userFiles-e8e871ae-42e8-431d-9c6f-2fb331d63875/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 191.336412 ms
18/02/28 23:22:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 23:22:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 436 ms on localhost (executor driver) (1/1)
18/02/28 23:22:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 23:22:26 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.452 s
18/02/28 23:22:26 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.582676 s
18/02/28 23:22:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:26 INFO SparkSqlParser: Parsing command: test
18/02/28 23:22:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 23:22:26 INFO SparkSqlParser: Parsing command: `test`
18/02/28 23:22:26 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49566 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 117.869135 ms
18/02/28 23:22:26 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 23:22:26 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 10.066006 ms
18/02/28 23:22:26 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 23:22:26 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:22:26 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 23:22:26 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:22:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 23:22:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 23:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 23:22:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49566 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:22:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 23:22:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:22:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 8.442635 ms
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 17.558476 ms
18/02/28 23:22:26 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 23:22:26 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:49566 (size: 384.0 B, free: 366.3 MB)
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 4.247411 ms
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 16.263729 ms
18/02/28 23:22:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 23:22:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 135 ms on localhost (executor driver) (1/1)
18/02/28 23:22:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 23:22:26 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.138 s
18/02/28 23:22:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:22:26 INFO DAGScheduler: running: Set()
18/02/28 23:22:26 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 23:22:26 INFO DAGScheduler: failed: Set()
18/02/28 23:22:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 23:22:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49566 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:22:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 23:22:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:22:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 23:22:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:22:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 23:22:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
18/02/28 23:22:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
18/02/28 23:22:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 23:22:26 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
18/02/28 23:22:26 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.208721 s
18/02/28 23:22:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:26 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 23:22:26 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:22:26 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:22:26 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:22:26 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 23:22:26 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:22:26 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 23:22:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 23:22:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 23:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 23:22:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49566 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:22:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 23:22:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:22:26 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 23:22:26 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:22:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 23:22:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (executor driver) (1/1)
18/02/28 23:22:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 23:22:26 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.011 s
18/02/28 23:22:26 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:22:26 INFO DAGScheduler: running: Set()
18/02/28 23:22:26 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 23:22:26 INFO DAGScheduler: failed: Set()
18/02/28 23:22:26 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 23:22:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 23:22:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49566 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:22:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 23:22:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:22:26 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 23:22:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:22:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/02/28 23:22:26 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
18/02/28 23:22:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
18/02/28 23:22:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 23:22:26 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.006 s
18/02/28 23:22:26 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.032379 s
18/02/28 23:22:26 INFO CodeGenerator: Code generated in 5.598545 ms
18/02/28 23:22:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 23:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17ee47468c8bb
18/02/28 23:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17ee47468c8bb` AS `zzz2`
WHERE (0 = 1)
18/02/28 23:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17ee47468c8bb`
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17ee49526c11
18/02/28 23:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17ee49526c11` AS `zzz3`
WHERE (0 = 1)
18/02/28 23:22:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:22:27 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_17ee49526c11`
18/02/28 23:22:27 INFO CodeGenerator: Code generated in 19.497459 ms
18/02/28 23:22:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:22:27 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:22:27 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 23:22:27 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:22:27 INFO DAGScheduler: Missing parents: List()
18/02/28 23:22:27 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 23:22:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 23:22:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.2 KB, free 366.2 MB)
18/02/28 23:22:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49566 (size: 9.2 KB, free: 366.3 MB)
18/02/28 23:22:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 23:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:22:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 23:22:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:22:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 23:22:27 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:22:27 INFO CodeGenerator: Code generated in 13.825913 ms
18/02/28 23:22:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 23:22:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 30 ms on localhost (executor driver) (1/1)
18/02/28 23:22:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 23:22:27 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.031 s
18/02/28 23:22:27 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.037524 s
18/02/28 23:22:27 INFO CodeGenerator: Code generated in 11.238131 ms
18/02/28 23:22:28 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 23:22:28 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 23:22:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 23:22:28 INFO MemoryStore: MemoryStore cleared
18/02/28 23:22:28 INFO BlockManager: BlockManager stopped
18/02/28 23:22:28 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 23:22:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 23:22:28 INFO SparkContext: Successfully stopped SparkContext
18/02/28 23:22:28 INFO ShutdownHookManager: Shutdown hook called
18/02/28 23:22:28 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-907ae66c-21f1-4d65-8dcf-98db153697ca
18/02/28 23:23:01 INFO SparkContext: Running Spark version 2.2.0
18/02/28 23:23:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/28 23:23:02 INFO SparkContext: Submitted application: sparklyr
18/02/28 23:23:02 INFO SecurityManager: Changing view acls to: wojciechksiazek
18/02/28 23:23:02 INFO SecurityManager: Changing modify acls to: wojciechksiazek
18/02/28 23:23:02 INFO SecurityManager: Changing view acls groups to: 
18/02/28 23:23:02 INFO SecurityManager: Changing modify acls groups to: 
18/02/28 23:23:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wojciechksiazek); groups with view permissions: Set(); users  with modify permissions: Set(wojciechksiazek); groups with modify permissions: Set()
18/02/28 23:23:02 INFO Utils: Successfully started service 'sparkDriver' on port 49647.
18/02/28 23:23:02 INFO SparkEnv: Registering MapOutputTracker
18/02/28 23:23:02 INFO SparkEnv: Registering BlockManagerMaster
18/02/28 23:23:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/02/28 23:23:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/02/28 23:23:02 INFO DiskBlockManager: Created local directory at /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/blockmgr-f4f9f18e-b7b6-487b-8b4d-f2cf4bcb1450
18/02/28 23:23:02 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/02/28 23:23:02 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/28 23:23:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/28 23:23:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/02/28 23:23:02 INFO SparkContext: Added JAR file:/Users/wojciechksiazek/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar at spark://127.0.0.1:49647/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856582579
18/02/28 23:23:02 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sparklyr/java/sparklyr-2.2-2.11.jar at spark://127.0.0.1:49647/jars/sparklyr-2.2-2.11.jar with timestamp 1519856582580
18/02/28 23:23:02 INFO Executor: Starting executor ID driver on host localhost
18/02/28 23:23:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49648.
18/02/28 23:23:02 INFO NettyBlockTransferService: Server created on 127.0.0.1:49648
18/02/28 23:23:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/02/28 23:23:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49648, None)
18/02/28 23:23:02 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49648 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49648, None)
18/02/28 23:23:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49648, None)
18/02/28 23:23:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49648, None)
18/02/28 23:23:02 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/02/28 23:23:02 INFO SharedState: loading hive config file: file:/Users/wojciechksiazek/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
18/02/28 23:23:02 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse').
18/02/28 23:23:02 INFO SharedState: Warehouse path is 'file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse'.
18/02/28 23:23:03 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/02/28 23:23:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/02/28 23:23:03 INFO ObjectStore: ObjectStore, initialize called
18/02/28 23:23:04 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/02/28 23:23:04 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/02/28 23:23:05 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/02/28 23:23:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:23:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:23:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:23:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:23:06 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/02/28 23:23:06 INFO ObjectStore: Initialized ObjectStore
18/02/28 23:23:06 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/02/28 23:23:06 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/02/28 23:23:06 INFO HiveMetaStore: Added admin role in metastore
18/02/28 23:23:06 INFO HiveMetaStore: Added public role in metastore
18/02/28 23:23:06 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/02/28 23:23:06 INFO HiveMetaStore: 0: get_all_databases
18/02/28 23:23:06 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_all_databases	
18/02/28 23:23:06 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/02/28 23:23:06 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/02/28 23:23:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/02/28 23:23:06 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/da5b76bb-58ee-49ef-8aab-6cc81797a5d2_resources
18/02/28 23:23:06 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/da5b76bb-58ee-49ef-8aab-6cc81797a5d2
18/02/28 23:23:06 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/da5b76bb-58ee-49ef-8aab-6cc81797a5d2
18/02/28 23:23:06 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/da5b76bb-58ee-49ef-8aab-6cc81797a5d2/_tmp_space.db
18/02/28 23:23:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:23:07 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:23:07 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:23:07 INFO HiveMetaStore: 0: get_database: global_temp
18/02/28 23:23:07 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/02/28 23:23:07 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/02/28 23:23:07 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/17091a37-9c46-437f-b02b-74102f9eb765_resources
18/02/28 23:23:07 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/17091a37-9c46-437f-b02b-74102f9eb765
18/02/28 23:23:07 INFO SessionState: Created local directory: /var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/wojciechksiazek/17091a37-9c46-437f-b02b-74102f9eb765
18/02/28 23:23:07 INFO SessionState: Created HDFS directory: /tmp/hive/wojciechksiazek/17091a37-9c46-437f-b02b-74102f9eb765/_tmp_space.db
18/02/28 23:23:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/wojciechksiazek/Desktop/Projects/sparklyrStemmer/tests/testthat/spark-warehouse
18/02/28 23:23:07 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/02/28 23:23:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/02/28 23:23:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:23:08 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:23:08 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:23:08 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:23:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/02/28 23:23:08 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/02/28 23:23:09 INFO SparkContext: Starting job: collect at utils.scala:58
18/02/28 23:23:09 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/02/28 23:23:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/02/28 23:23:09 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:23:09 INFO DAGScheduler: Missing parents: List()
18/02/28 23:23:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55), which has no missing parents
18/02/28 23:23:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB)
18/02/28 23:23:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 366.3 MB)
18/02/28 23:23:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49648 (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:23:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:55) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/02/28 23:23:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:23:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/02/28 23:23:09 INFO Executor: Fetching spark://127.0.0.1:49647/jars/com.github.master_spark-stemming_2.10-0.2.0.jar with timestamp 1519856582579
18/02/28 23:23:09 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49647 after 11 ms (0 ms spent in bootstraps)
18/02/28 23:23:09 INFO Utils: Fetching spark://127.0.0.1:49647/jars/com.github.master_spark-stemming_2.10-0.2.0.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-fe599834-30f1-48cb-b397-be349dc3dfa2/userFiles-69e0a40b-8e02-45c0-9d6f-7aeba510b249/fetchFileTemp8331221640820555945.tmp
18/02/28 23:23:09 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-fe599834-30f1-48cb-b397-be349dc3dfa2/userFiles-69e0a40b-8e02-45c0-9d6f-7aeba510b249/com.github.master_spark-stemming_2.10-0.2.0.jar to class loader
18/02/28 23:23:09 INFO Executor: Fetching spark://127.0.0.1:49647/jars/sparklyr-2.2-2.11.jar with timestamp 1519856582580
18/02/28 23:23:09 INFO Utils: Fetching spark://127.0.0.1:49647/jars/sparklyr-2.2-2.11.jar to /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-fe599834-30f1-48cb-b397-be349dc3dfa2/userFiles-69e0a40b-8e02-45c0-9d6f-7aeba510b249/fetchFileTemp5133623933092265450.tmp
18/02/28 23:23:09 INFO Executor: Adding file:/private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-fe599834-30f1-48cb-b397-be349dc3dfa2/userFiles-69e0a40b-8e02-45c0-9d6f-7aeba510b249/sparklyr-2.2-2.11.jar to class loader
18/02/28 23:23:09 INFO CodeGenerator: Code generated in 179.78128 ms
18/02/28 23:23:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
18/02/28 23:23:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 458 ms on localhost (executor driver) (1/1)
18/02/28 23:23:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/02/28 23:23:09 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.476 s
18/02/28 23:23:09 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.614386 s
18/02/28 23:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:09 INFO SparkSqlParser: Parsing command: test
18/02/28 23:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
18/02/28 23:23:09 INFO SparkSqlParser: Parsing command: `test`
18/02/28 23:23:09 INFO ContextCleaner: Cleaned accumulator 0
18/02/28 23:23:09 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49648 in memory (size: 3.4 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO ContextCleaner: Cleaned accumulator 51
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 17.182388 ms
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 10.651047 ms
18/02/28 23:23:10 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/02/28 23:23:10 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:23:10 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/02/28 23:23:10 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/02/28 23:23:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/02/28 23:23:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/02/28 23:23:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.3 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49648 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/02/28 23:23:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:23:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 7.718995 ms
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 16.294934 ms
18/02/28 23:23:10 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 384.0 B, free 366.3 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:49648 (size: 384.0 B, free: 366.3 MB)
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 3.85837 ms
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 16.574472 ms
18/02/28 23:23:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
18/02/28 23:23:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 138 ms on localhost (executor driver) (1/1)
18/02/28 23:23:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/02/28 23:23:10 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.139 s
18/02/28 23:23:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:23:10 INFO DAGScheduler: running: Set()
18/02/28 23:23:10 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/02/28 23:23:10 INFO DAGScheduler: failed: Set()
18/02/28 23:23:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49648 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/02/28 23:23:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:23:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/02/28 23:23:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:23:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/02/28 23:23:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
18/02/28 23:23:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on localhost (executor driver) (1/1)
18/02/28 23:23:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/02/28 23:23:10 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.034 s
18/02/28 23:23:10 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.215880 s
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
18/02/28 23:23:10 INFO HiveMetaStore: 0: get_database: default
18/02/28 23:23:10 INFO audit: ugi=wojciechksiazek	ip=unknown-ip-addr	cmd=get_database: default	
18/02/28 23:23:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:23:10 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:211)
18/02/28 23:23:10 INFO DAGScheduler: Got job 2 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:23:10 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:211)
18/02/28 23:23:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/02/28 23:23:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/02/28 23:23:10 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211), which has no missing parents
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 366.3 MB)
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.2 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49648 (size: 7.3 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/02/28 23:23:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4841 bytes)
18/02/28 23:23:10 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/02/28 23:23:10 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:23:10 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
18/02/28 23:23:10 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
18/02/28 23:23:10 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/02/28 23:23:10 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:211) finished in 0.011 s
18/02/28 23:23:10 INFO DAGScheduler: looking for newly runnable stages
18/02/28 23:23:10 INFO DAGScheduler: running: Set()
18/02/28 23:23:10 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/02/28 23:23:10 INFO DAGScheduler: failed: Set()
18/02/28 23:23:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211), which has no missing parents
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49648 (size: 3.7 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/02/28 23:23:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
18/02/28 23:23:10 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/02/28 23:23:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/02/28 23:23:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/02/28 23:23:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1624 bytes result sent to driver
18/02/28 23:23:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
18/02/28 23:23:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/02/28 23:23:10 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:211) finished in 0.007 s
18/02/28 23:23:10 INFO DAGScheduler: Job 2 finished: collect at utils.scala:211, took 0.033249 s
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 7.38328 ms
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz1`
WHERE (0 = 1)
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17f5350465b18
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17f5350465b18` AS `zzz2`
WHERE (0 = 1)
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17f5350465b18`
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: sparklyr_tmp_17f532ba74ca7
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_17f532ba74ca7` AS `zzz3`
WHERE (0 = 1)
18/02/28 23:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/02/28 23:23:10 INFO SparkSqlParser: Parsing command: SELECT `stemmedTokens`
FROM `sparklyr_tmp_17f532ba74ca7`
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 22.390144 ms
18/02/28 23:23:10 INFO SparkContext: Starting job: collect at utils.scala:211
18/02/28 23:23:10 INFO DAGScheduler: Got job 3 (collect at utils.scala:211) with 1 output partitions
18/02/28 23:23:10 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:211)
18/02/28 23:23:10 INFO DAGScheduler: Parents of final stage: List()
18/02/28 23:23:10 INFO DAGScheduler: Missing parents: List()
18/02/28 23:23:10 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211), which has no missing parents
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 19.8 KB, free 366.2 MB)
18/02/28 23:23:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KB, free 366.2 MB)
18/02/28 23:23:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49648 (size: 9.1 KB, free: 366.3 MB)
18/02/28 23:23:10 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/02/28 23:23:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at collect at utils.scala:211) (first 15 tasks are for partitions Vector(0))
18/02/28 23:23:10 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/02/28 23:23:10 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
18/02/28 23:23:10 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/02/28 23:23:10 INFO BlockManager: Found block rdd_9_0 locally
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 15.153754 ms
18/02/28 23:23:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1402 bytes result sent to driver
18/02/28 23:23:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (executor driver) (1/1)
18/02/28 23:23:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/02/28 23:23:10 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:211) finished in 0.032 s
18/02/28 23:23:10 INFO DAGScheduler: Job 3 finished: collect at utils.scala:211, took 0.040621 s
18/02/28 23:23:10 INFO CodeGenerator: Code generated in 12.492009 ms
18/02/28 23:23:12 INFO SparkContext: Invoking stop() from shutdown hook
18/02/28 23:23:12 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/02/28 23:23:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/02/28 23:23:12 INFO MemoryStore: MemoryStore cleared
18/02/28 23:23:12 INFO BlockManager: BlockManager stopped
18/02/28 23:23:12 INFO BlockManagerMaster: BlockManagerMaster stopped
18/02/28 23:23:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/02/28 23:23:12 INFO SparkContext: Successfully stopped SparkContext
18/02/28 23:23:12 INFO ShutdownHookManager: Shutdown hook called
18/02/28 23:23:12 INFO ShutdownHookManager: Deleting directory /private/var/folders/dp/c7ps37ts71b7p6r4hwf6snw40000gn/T/spark-fe599834-30f1-48cb-b397-be349dc3dfa2
